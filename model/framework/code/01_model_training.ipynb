{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSGHAyXwPsQV"
   },
   "source": [
    "# Model training tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 7292,
     "status": "ok",
     "timestamp": 1705453445939,
     "user": {
      "displayName": "leila yesufu",
      "userId": "04090599876914949365"
     },
     "user_tz": -60
    },
    "id": "Weq9bxmL6NCh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gturon/miniconda3/envs/chem/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-02-06 12:53:05,738\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-02-06 12:53:05,803\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from flaml import AutoML\n",
    "from sklearn.metrics import auc, roc_curve, classification_report\n",
    "\n",
    "\n",
    "DATAPATH = \"../data\"\n",
    "FIGUREPATH = \"../figures\"\n",
    "MODELPATH = \"../../checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PADEL Descriptors\n",
    "The authors of the publication originally try PADEL descriptors to train the model. Because Padel descriptors take a long time to be calculated, we only do it once for the whole file and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from padelpy import from_smiles\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATAPATH, \"training_set.csv\"))\n",
    "unprocessed_idx = []\n",
    "descs = []\n",
    "for i,smi in enumerate(df[\"smiles\"].tolist()):\n",
    "    try:\n",
    "        descriptors = from_smiles([smi])\n",
    "        descs.extend(descriptors)\n",
    "    except:\n",
    "        print(f\"Error processing SMILES: {smi}\")\n",
    "        unprocessed_idx += [i]\n",
    "\n",
    "descs_df = pd.DataFrame(descs)\n",
    "\n",
    "df_ = df.drop(unprocessed_idx)\n",
    "df_padel = pd.concat([df_.reset_index(drop=True), descs_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df_padel.to_csv(os.path.join(DATAPATH, \"training_set_padel.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_padel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATAPATH, \"training_set_padel.csv\"))\n",
    "df = df[[\"smiles\", \"inchikey\", \"outcome\"]]\n",
    "df.to_csv(os.path.join(DATAPATH, \"training_set_clean.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLITS\n",
    "\n",
    "# we will always use the same train test split, saving the files to reuse them\n",
    "# ONLY RUN ONCE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def random_split(df, size):\n",
    "    indices = np.arange(len(df))\n",
    "    X_train, X_test, y_train, y_test, i_train, i_test = train_test_split(df[\"smiles\"], df[\"outcome\"], indices, test_size=size, stratify=df[\"outcome\"])\n",
    "    train = df.iloc[i_train]\n",
    "    test = df.iloc[i_test]\n",
    "    return train, test\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATAPATH, \"training_set_clean.csv\"))\n",
    "for i in range(5):\n",
    "    train, test = random_split(df, 0.2)\n",
    "    train.to_csv(os.path.join(DATAPATH, \"train_test_splits\", \"train_{}.csv\".format(i)), index=False)\n",
    "    test.to_csv(os.path.join(DATAPATH, \"train_test_splits\", \"test_{}.csv\".format(i)), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML\n",
    "We use AutoML for the Padel descriptors and LazyQSAR for the Ersilia Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padel descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training with PADEL Descriptors\n",
    "%%capture\n",
    "\n",
    "import logging\n",
    "logging.getLogger('flaml.automl').setLevel(logging.WARNING) # Suppress FLAML INFO logging\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATAPATH, \"training_set_padel.csv\"))\n",
    "#impute any missing values\n",
    "for column in df.columns[3:]:\n",
    "    column_mean = df[column].mean()\n",
    "    df[column].fillna(column_mean, inplace=True)\n",
    "\n",
    "#change infinity values\n",
    "df.replace([np.inf, -np.inf], 1e6, inplace=True)\n",
    "\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\", train_file))\n",
    "    test = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\",test_file))\n",
    "    train_descs = pd.merge(train, df, on=['inchikey', \"smiles\", \"outcome\"], how='left')\n",
    "    test_descs = pd.merge(test, df, on =['inchikey', \"smiles\", \"outcome\"], how = \"left\")\n",
    "    y_train = train[\"outcome\"]\n",
    "    y_test = test[\"outcome\"]\n",
    "    X_train = train_descs.iloc[:, 4:]\n",
    "    X_test = test_descs.iloc[:, 4:]\n",
    "\n",
    "    mdl = AutoML(task=\"classification\", time_budget=600, logistic_max_iter=40000)\n",
    "    mdl.fit(X_train, y_train)\n",
    "    y_pred = mdl.predict_proba(X_test)[:,1]\n",
    "    y_pred_bin = [1 if y > 0.5 else 0 for y in y_pred]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(y_test)\n",
    "    all_predictions.extend(y_pred_bin)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoML', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.savefig(os.path.join(FIGUREPATH, \"Padel_AutoML_600s.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ersilia Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import lazyqsar as lq\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train_set = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\", train_file))\n",
    "    test_set = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\",test_file))\n",
    "    X_train = train_set[\"smiles\"]\n",
    "    y_train = train_set[\"outcome\"]\n",
    "    X_test = test_set[\"smiles\"]\n",
    "    y_test = test_set[\"outcome\"]\n",
    "\n",
    "\n",
    "    # Fit the model on the training set for the current fold\n",
    "    model = lq.ErsiliaBinaryClassifier(time_budget_sec=600, estimator_list=[\"rf\", \"lgbm\", \"xgboost\"])\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Obtain predictions and true labels for the current fold\n",
    "    y_hat_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_hat_proba)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(y_test)\n",
    "    all_predictions.extend(y_pred)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoML Morgan', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.savefig(os.path.join(FIGUREPATH, \"Ersilia_AutoML_600s.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morgan Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train_set = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\", train_file))\n",
    "    test_set = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\",test_file))\n",
    "    X_train = train_set[\"smiles\"]\n",
    "    y_train = train_set[\"outcome\"]\n",
    "    X_test = test_set[\"smiles\"]\n",
    "    y_test = test_set[\"outcome\"]\n",
    "\n",
    "\n",
    "    # Fit the model on the training set for the current fold\n",
    "    model = lq.MorganBinaryClassifier(time_budget_sec=600, estimator_list=[\"rf\", \"lgbm\", \"xgboost\"])\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Obtain predictions and true labels for the current fold\n",
    "    y_hat_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_hat_proba)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(y_test)\n",
    "    all_predictions.extend(y_pred)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoML Morgan', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.savefig(os.path.join(FIGUREPATH, \"Morgan_AutoML_600s.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the AutoML models, the Padel is the one that does better, followed by Ersilia Embeddings. Padel descriptors are slower to generate, so we might want to use Ersilia Embeddings instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon\n",
    "We will try the AutoGluon method with the three descriptors used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATAPATH, \"training_set_padel.csv\"))\n",
    "#impute any missing values\n",
    "for column in df.columns[3:]:\n",
    "    column_mean = df[column].mean()\n",
    "    df[column].fillna(column_mean, inplace=True)\n",
    "\n",
    "#change infinity values\n",
    "df.replace([np.inf, -np.inf], 1e6, inplace=True)\n",
    "\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\", train_file))\n",
    "    test = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\",test_file))\n",
    "    train_descs = pd.merge(train, df, on=['inchikey', \"smiles\", \"outcome\"], how='left')\n",
    "    test_descs = pd.merge(test, df, on =['inchikey', \"smiles\", \"outcome\"], how = \"left\")\n",
    "    y_train = train[\"outcome\"]\n",
    "    y_test = test[\"outcome\"]\n",
    "    X_train = train_descs.iloc[:, 4:]\n",
    "    X_test = test_descs.iloc[:, 4:]\n",
    "    X_train[\"outcome\"] = y_train #add outcome again for the Tabular Predictor requirement\n",
    "\n",
    "    fit_args = {}\n",
    "    fit_args['time_limit'] =  600\n",
    "    predictor = TabularPredictor(label=\"outcome\").fit(X_train,presets=\"best_quality\", **fit_args)\n",
    "    y_pred = predictor.predict_proba(X_test, as_pandas=False)[:,1]\n",
    "    y_pred_bin = [1 if y > 0.5 else 0 for y in y_pred]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(y_test)\n",
    "    all_predictions.extend(y_pred_bin)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoGluon', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.savefig(os.path.join(FIGUREPATH, \"Padel_AutoGluon_600s.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Ersilia embeddings\n",
    "from eosce.models import ErsiliaCompoundEmbeddings\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\", train_file))\n",
    "    test = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\",test_file))\n",
    "    y_train = train[\"outcome\"]\n",
    "    y_test = test[\"outcome\"]\n",
    "    model = ErsiliaCompoundEmbeddings()\n",
    "    X_train = model.transform(train[\"smiles\"].tolist())\n",
    "    X_train = pd.DataFrame(X_train, columns=[\"eosce_{}\".format(i) for i in range(len(X_train[0]))])\n",
    "    X_test = model.transform(test[\"smiles\"].tolist())\n",
    "    X_test = pd.DataFrame(X_test, columns=[\"eosce_{}\".format(i) for i in range(len(X_test[0]))])\n",
    "    X_train[\"outcome\"] = y_train #add outcome again for the Tabular Predictor requirement\n",
    "\n",
    "    fit_args = {}\n",
    "    fit_args['time_limit'] =  600\n",
    "    predictor = TabularPredictor(label=\"outcome\").fit(X_train,presets=\"best_quality\", **fit_args)\n",
    "    y_pred = predictor.predict_proba(X_test, as_pandas=False)[:,1]\n",
    "    y_pred_bin = [1 if y > 0.5 else 0 for y in y_pred]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(y_test)\n",
    "    all_predictions.extend(y_pred_bin)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoGluon', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.savefig(os.path.join(FIGUREPATH, \"Ersilia_AutoGluon_600s.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Morgan embeddings\n",
    "\n",
    "from lazyqsar.descriptors.descriptors import MorganDescriptor\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "all_true_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    train_file = f\"train_{i}.csv\"\n",
    "    test_file = f\"test_{i}.csv\"\n",
    "    train = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\", train_file))\n",
    "    test = pd.read_csv(os.path.join(DATAPATH, \"train_test_splits\",test_file))\n",
    "    y_train = train[\"outcome\"]\n",
    "    y_test = test[\"outcome\"]\n",
    "    model = MorganDescriptor()\n",
    "    model.fit(train[\"smiles\"].tolist())\n",
    "    X_train = model.transform(train[\"smiles\"].tolist())\n",
    "    X_test = model.transform(test[\"smiles\"].tolist())\n",
    "    X_train[\"outcome\"] = y_train #add outcome again for the Tabular Predictor requirement\n",
    "\n",
    "    fit_args = {}\n",
    "    fit_args['time_limit'] =  600\n",
    "    predictor = TabularPredictor(label=\"outcome\").fit(X_train,presets=\"best_quality\", **fit_args)\n",
    "    y_pred = predictor.predict_proba(X_test, as_pandas=False)[:,1]\n",
    "    y_pred_bin = [1 if y > 0.5 else 0 for y in y_pred]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "\n",
    "    # Accumulate true labels and predictions\n",
    "    all_true_labels.extend(y_test)\n",
    "    all_predictions.extend(y_pred_bin)\n",
    "\n",
    "# Calculate and print the average classification report\n",
    "print(\"\\nAverage Classification Report Across All Folds:\\n\")\n",
    "print(classification_report(all_true_labels, all_predictions))\n",
    "\n",
    "# Calculate mean ROC curve and AUC\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "# Plot mean ROC curve with boundaries\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('Cross-Validation ROC of AutoGluon', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "plt.savefig(os.path.join(FIGUREPATH, \"Morgan_AutoGluon_600s.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5rPWLM1SD8f"
   },
   "source": [
    "# Final Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 02-06 12:53:14] {1679} INFO - task = classification\n",
      "[flaml.automl.logger: 02-06 12:53:14] {1690} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 02-06 12:53:14] {1788} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 02-06 12:53:14] {1900} INFO - List of ML learners in AutoML Run: ['rf', 'lgbm', 'xgboost']\n",
      "[flaml.automl.logger: 02-06 12:53:14] {2218} INFO - iteration 0, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:14] {2344} INFO - Estimated sufficient time budget=879s. Estimated necessary time budget=1s.\n",
      "[flaml.automl.logger: 02-06 12:53:14] {2391} INFO -  at 0.1s,\testimator rf's best error=0.4151,\tbest estimator rf's best error=0.4151\n",
      "[flaml.automl.logger: 02-06 12:53:14] {2218} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:15] {2391} INFO -  at 0.6s,\testimator lgbm's best error=0.3677,\tbest estimator lgbm's best error=0.3677\n",
      "[flaml.automl.logger: 02-06 12:53:15] {2218} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2391} INFO -  at 1.5s,\testimator xgboost's best error=0.3914,\tbest estimator lgbm's best error=0.3677\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2218} INFO - iteration 3, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2391} INFO -  at 1.6s,\testimator rf's best error=0.4151,\tbest estimator lgbm's best error=0.3677\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2218} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2391} INFO -  at 1.7s,\testimator rf's best error=0.4027,\tbest estimator lgbm's best error=0.3677\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2218} INFO - iteration 5, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2391} INFO -  at 1.8s,\testimator rf's best error=0.4022,\tbest estimator lgbm's best error=0.3677\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2218} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2391} INFO -  at 2.1s,\testimator lgbm's best error=0.3677,\tbest estimator lgbm's best error=0.3677\n",
      "[flaml.automl.logger: 02-06 12:53:16] {2218} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:17] {2391} INFO -  at 2.6s,\testimator lgbm's best error=0.3440,\tbest estimator lgbm's best error=0.3440\n",
      "[flaml.automl.logger: 02-06 12:53:17] {2218} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:17] {2391} INFO -  at 3.2s,\testimator lgbm's best error=0.3440,\tbest estimator lgbm's best error=0.3440\n",
      "[flaml.automl.logger: 02-06 12:53:17] {2218} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:18] {2391} INFO -  at 3.6s,\testimator lgbm's best error=0.3440,\tbest estimator lgbm's best error=0.3440\n",
      "[flaml.automl.logger: 02-06 12:53:18] {2218} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:18] {2391} INFO -  at 4.0s,\testimator lgbm's best error=0.3440,\tbest estimator lgbm's best error=0.3440\n",
      "[flaml.automl.logger: 02-06 12:53:18] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:53:19] {2391} INFO -  at 4.5s,\testimator xgboost's best error=0.3721,\tbest estimator lgbm's best error=0.3440\n",
      "[flaml.automl.logger: 02-06 12:53:19] {2218} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:53:19] {2391} INFO -  at 5.0s,\testimator xgboost's best error=0.3387,\tbest estimator xgboost's best error=0.3387\n",
      "[flaml.automl.logger: 02-06 12:53:19] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:53:19] {2391} INFO -  at 5.3s,\testimator xgboost's best error=0.3387,\tbest estimator xgboost's best error=0.3387\n",
      "[flaml.automl.logger: 02-06 12:53:19] {2218} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:53:20] {2391} INFO -  at 6.1s,\testimator xgboost's best error=0.3387,\tbest estimator xgboost's best error=0.3387\n",
      "[flaml.automl.logger: 02-06 12:53:20] {2218} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:21] {2391} INFO -  at 6.6s,\testimator lgbm's best error=0.3440,\tbest estimator xgboost's best error=0.3387\n",
      "[flaml.automl.logger: 02-06 12:53:21] {2218} INFO - iteration 16, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:53:21] {2391} INFO -  at 7.0s,\testimator xgboost's best error=0.3387,\tbest estimator xgboost's best error=0.3387\n",
      "[flaml.automl.logger: 02-06 12:53:21] {2218} INFO - iteration 17, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:22] {2391} INFO -  at 7.6s,\testimator lgbm's best error=0.3308,\tbest estimator lgbm's best error=0.3308\n",
      "[flaml.automl.logger: 02-06 12:53:22] {2218} INFO - iteration 18, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:53:22] {2391} INFO -  at 8.4s,\testimator xgboost's best error=0.3378,\tbest estimator lgbm's best error=0.3308\n",
      "[flaml.automl.logger: 02-06 12:53:22] {2218} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:23] {2391} INFO -  at 8.8s,\testimator lgbm's best error=0.3237,\tbest estimator lgbm's best error=0.3237\n",
      "[flaml.automl.logger: 02-06 12:53:23] {2218} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:23] {2391} INFO -  at 9.3s,\testimator lgbm's best error=0.3237,\tbest estimator lgbm's best error=0.3237\n",
      "[flaml.automl.logger: 02-06 12:53:23] {2218} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:24] {2391} INFO -  at 10.2s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:24] {2218} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:26] {2391} INFO -  at 11.6s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:26] {2218} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:26] {2391} INFO -  at 12.2s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:26] {2218} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:27] {2391} INFO -  at 12.9s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:27] {2218} INFO - iteration 25, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:28] {2391} INFO -  at 13.9s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:28] {2218} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:29] {2391} INFO -  at 15.0s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:29] {2218} INFO - iteration 27, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:30] {2391} INFO -  at 15.8s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:30] {2218} INFO - iteration 28, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2391} INFO -  at 16.4s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2218} INFO - iteration 29, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2391} INFO -  at 16.6s,\testimator rf's best error=0.4022,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2218} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2391} INFO -  at 16.7s,\testimator rf's best error=0.3592,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2218} INFO - iteration 31, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2391} INFO -  at 16.8s,\testimator rf's best error=0.3592,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2218} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2391} INFO -  at 17.3s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:31] {2218} INFO - iteration 33, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:32] {2391} INFO -  at 17.7s,\testimator rf's best error=0.3347,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:32] {2218} INFO - iteration 34, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:32] {2391} INFO -  at 17.9s,\testimator rf's best error=0.3347,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:32] {2218} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:33] {2391} INFO -  at 18.7s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:33] {2218} INFO - iteration 36, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:33] {2391} INFO -  at 19.1s,\testimator rf's best error=0.3347,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:33] {2218} INFO - iteration 37, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:33] {2391} INFO -  at 19.4s,\testimator rf's best error=0.3347,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:33] {2218} INFO - iteration 38, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:34] {2391} INFO -  at 19.6s,\testimator rf's best error=0.3347,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:34] {2218} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:34] {2391} INFO -  at 20.0s,\testimator rf's best error=0.3326,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:34] {2218} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:35] {2391} INFO -  at 20.8s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:35] {2218} INFO - iteration 41, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:35] {2391} INFO -  at 21.1s,\testimator rf's best error=0.3326,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:35] {2218} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:36] {2391} INFO -  at 22.1s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:36] {2218} INFO - iteration 43, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:53:37] {2391} INFO -  at 22.9s,\testimator xgboost's best error=0.3378,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:37] {2218} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:37] {2391} INFO -  at 23.3s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:37] {2218} INFO - iteration 45, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:38] {2391} INFO -  at 24.2s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:38] {2218} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:39] {2391} INFO -  at 25.1s,\testimator lgbm's best error=0.3131,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:39] {2218} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:40] {2391} INFO -  at 25.8s,\testimator rf's best error=0.3194,\tbest estimator lgbm's best error=0.3131\n",
      "[flaml.automl.logger: 02-06 12:53:40] {2218} INFO - iteration 48, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:40] {2391} INFO -  at 26.3s,\testimator rf's best error=0.3091,\tbest estimator rf's best error=0.3091\n",
      "[flaml.automl.logger: 02-06 12:53:40] {2218} INFO - iteration 49, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:41] {2391} INFO -  at 27.0s,\testimator rf's best error=0.3091,\tbest estimator rf's best error=0.3091\n",
      "[flaml.automl.logger: 02-06 12:53:41] {2218} INFO - iteration 50, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:42] {2391} INFO -  at 27.4s,\testimator rf's best error=0.3045,\tbest estimator rf's best error=0.3045\n",
      "[flaml.automl.logger: 02-06 12:53:42] {2218} INFO - iteration 51, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:42] {2391} INFO -  at 28.0s,\testimator rf's best error=0.3045,\tbest estimator rf's best error=0.3045\n",
      "[flaml.automl.logger: 02-06 12:53:42] {2218} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:42] {2391} INFO -  at 28.4s,\testimator rf's best error=0.3045,\tbest estimator rf's best error=0.3045\n",
      "[flaml.automl.logger: 02-06 12:53:42] {2218} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:43] {2391} INFO -  at 28.8s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:43] {2218} INFO - iteration 54, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:43] {2391} INFO -  at 29.3s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:43] {2218} INFO - iteration 55, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:44] {2391} INFO -  at 29.6s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:44] {2218} INFO - iteration 56, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:44] {2391} INFO -  at 30.3s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:44] {2218} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:45] {2391} INFO -  at 30.6s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:45] {2218} INFO - iteration 58, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:45] {2391} INFO -  at 31.1s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:45] {2218} INFO - iteration 59, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:46] {2391} INFO -  at 31.4s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:46] {2218} INFO - iteration 60, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:46] {2391} INFO -  at 31.9s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:46] {2218} INFO - iteration 61, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:46] {2391} INFO -  at 32.2s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:46] {2218} INFO - iteration 62, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:47] {2391} INFO -  at 32.6s,\testimator rf's best error=0.3008,\tbest estimator rf's best error=0.3008\n",
      "[flaml.automl.logger: 02-06 12:53:47] {2218} INFO - iteration 63, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:47] {2391} INFO -  at 33.0s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:47] {2218} INFO - iteration 64, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:48] {2391} INFO -  at 33.7s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:48] {2218} INFO - iteration 65, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:48] {2391} INFO -  at 33.9s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:48] {2218} INFO - iteration 66, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:48] {2391} INFO -  at 34.3s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:48] {2218} INFO - iteration 67, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:49] {2391} INFO -  at 34.8s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:49] {2218} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:50] {2391} INFO -  at 35.6s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:50] {2218} INFO - iteration 69, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:50] {2391} INFO -  at 35.8s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:50] {2218} INFO - iteration 70, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:50] {2391} INFO -  at 36.0s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:50] {2218} INFO - iteration 71, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:51] {2391} INFO -  at 37.0s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:51] {2218} INFO - iteration 72, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:52] {2391} INFO -  at 37.6s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:52] {2218} INFO - iteration 73, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:53] {2391} INFO -  at 38.5s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:53] {2218} INFO - iteration 74, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:53] {2391} INFO -  at 39.2s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:53] {2218} INFO - iteration 75, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:54] {2391} INFO -  at 39.5s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:54] {2218} INFO - iteration 76, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:54] {2391} INFO -  at 40.0s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:54] {2218} INFO - iteration 77, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:54] {2391} INFO -  at 40.4s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:54] {2218} INFO - iteration 78, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:55] {2391} INFO -  at 41.0s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:55] {2218} INFO - iteration 79, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:56] {2391} INFO -  at 42.1s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:56] {2218} INFO - iteration 80, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:56] {2391} INFO -  at 42.4s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:56] {2218} INFO - iteration 81, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:57] {2391} INFO -  at 43.0s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:57] {2218} INFO - iteration 82, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:57] {2391} INFO -  at 43.4s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:57] {2218} INFO - iteration 83, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:53:58] {2391} INFO -  at 43.7s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:58] {2218} INFO - iteration 84, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:58] {2391} INFO -  at 44.1s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:58] {2218} INFO - iteration 85, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:59] {2391} INFO -  at 44.7s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:59] {2218} INFO - iteration 86, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:53:59] {2391} INFO -  at 45.1s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:53:59] {2218} INFO - iteration 87, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:00] {2391} INFO -  at 45.6s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:00] {2218} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:00] {2391} INFO -  at 46.0s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:00] {2218} INFO - iteration 89, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:01] {2391} INFO -  at 46.5s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:01] {2218} INFO - iteration 90, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:02] {2391} INFO -  at 47.8s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:02] {2218} INFO - iteration 91, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:02] {2391} INFO -  at 48.2s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:02] {2218} INFO - iteration 92, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:03] {2391} INFO -  at 48.7s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:03] {2218} INFO - iteration 93, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:03] {2391} INFO -  at 49.1s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:03] {2218} INFO - iteration 94, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:03] {2391} INFO -  at 49.4s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:03] {2218} INFO - iteration 95, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:04] {2391} INFO -  at 49.6s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:04] {2218} INFO - iteration 96, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:04] {2391} INFO -  at 50.2s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:04] {2218} INFO - iteration 97, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:05] {2391} INFO -  at 50.6s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:05] {2218} INFO - iteration 98, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:05] {2391} INFO -  at 51.1s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:05] {2218} INFO - iteration 99, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:06] {2391} INFO -  at 51.6s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:06] {2218} INFO - iteration 100, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:06] {2391} INFO -  at 51.9s,\testimator rf's best error=0.3005,\tbest estimator rf's best error=0.3005\n",
      "[flaml.automl.logger: 02-06 12:54:06] {2218} INFO - iteration 101, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:07] {2391} INFO -  at 52.5s,\testimator rf's best error=0.2973,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:07] {2218} INFO - iteration 102, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:07] {2391} INFO -  at 52.9s,\testimator rf's best error=0.2973,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:07] {2218} INFO - iteration 103, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:08] {2391} INFO -  at 53.5s,\testimator rf's best error=0.2973,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:08] {2218} INFO - iteration 104, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:08] {2391} INFO -  at 53.9s,\testimator rf's best error=0.2973,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:08] {2218} INFO - iteration 105, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:10] {2391} INFO -  at 55.8s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:10] {2218} INFO - iteration 106, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:11] {2391} INFO -  at 56.4s,\testimator rf's best error=0.2973,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:11] {2218} INFO - iteration 107, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:12] {2391} INFO -  at 57.6s,\testimator lgbm's best error=0.3131,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:12] {2218} INFO - iteration 108, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:12] {2391} INFO -  at 58.1s,\testimator rf's best error=0.2973,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:12] {2218} INFO - iteration 109, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:13] {2391} INFO -  at 58.8s,\testimator rf's best error=0.2973,\tbest estimator rf's best error=0.2973\n",
      "[flaml.automl.logger: 02-06 12:54:13] {2218} INFO - iteration 110, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:13] {2391} INFO -  at 59.4s,\testimator lgbm's best error=0.2972,\tbest estimator lgbm's best error=0.2972\n",
      "[flaml.automl.logger: 02-06 12:54:13] {2218} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:16] {2391} INFO -  at 61.5s,\testimator lgbm's best error=0.2972,\tbest estimator lgbm's best error=0.2972\n",
      "[flaml.automl.logger: 02-06 12:54:16] {2218} INFO - iteration 112, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:54:17] {2391} INFO -  at 62.9s,\testimator xgboost's best error=0.3378,\tbest estimator lgbm's best error=0.2972\n",
      "[flaml.automl.logger: 02-06 12:54:17] {2218} INFO - iteration 113, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:17] {2391} INFO -  at 63.4s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2972\n",
      "[flaml.automl.logger: 02-06 12:54:17] {2218} INFO - iteration 114, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:18] {2391} INFO -  at 64.1s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2972\n",
      "[flaml.automl.logger: 02-06 12:54:18] {2218} INFO - iteration 115, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:20] {2391} INFO -  at 66.2s,\testimator lgbm's best error=0.2972,\tbest estimator lgbm's best error=0.2972\n",
      "[flaml.automl.logger: 02-06 12:54:20] {2218} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:21] {2391} INFO -  at 67.3s,\testimator lgbm's best error=0.2972,\tbest estimator lgbm's best error=0.2972\n",
      "[flaml.automl.logger: 02-06 12:54:21] {2218} INFO - iteration 117, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:22] {2391} INFO -  at 68.2s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2972\n",
      "[flaml.automl.logger: 02-06 12:54:22] {2218} INFO - iteration 118, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:26] {2391} INFO -  at 71.8s,\testimator lgbm's best error=0.2964,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:26] {2218} INFO - iteration 119, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:27] {2391} INFO -  at 73.2s,\testimator lgbm's best error=0.2964,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:27] {2218} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:33] {2391} INFO -  at 79.0s,\testimator lgbm's best error=0.2964,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:33] {2218} INFO - iteration 121, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:36] {2391} INFO -  at 81.6s,\testimator lgbm's best error=0.2964,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:36] {2218} INFO - iteration 122, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:36] {2391} INFO -  at 82.0s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:36] {2218} INFO - iteration 123, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:36] {2391} INFO -  at 82.3s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:36] {2218} INFO - iteration 124, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:37] {2391} INFO -  at 83.0s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:37] {2218} INFO - iteration 125, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:38] {2391} INFO -  at 83.7s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:38] {2218} INFO - iteration 126, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:38] {2391} INFO -  at 84.2s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:38] {2218} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:47] {2391} INFO -  at 92.8s,\testimator lgbm's best error=0.2964,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:47] {2218} INFO - iteration 128, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:47] {2391} INFO -  at 93.4s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:47] {2218} INFO - iteration 129, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:48] {2391} INFO -  at 93.8s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2964\n",
      "[flaml.automl.logger: 02-06 12:54:48] {2218} INFO - iteration 130, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:50] {2391} INFO -  at 95.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:54:50] {2218} INFO - iteration 131, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:54:50] {2391} INFO -  at 96.2s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:54:50] {2218} INFO - iteration 132, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:54] {2391} INFO -  at 100.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:54:54] {2218} INFO - iteration 133, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:54:55] {2391} INFO -  at 101.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:54:55] {2218} INFO - iteration 134, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:54:57] {2391} INFO -  at 102.6s,\testimator xgboost's best error=0.3284,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:54:57] {2218} INFO - iteration 135, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:00] {2391} INFO -  at 105.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:00] {2218} INFO - iteration 136, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:55:00] {2391} INFO -  at 106.3s,\testimator rf's best error=0.2973,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:00] {2218} INFO - iteration 137, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:01] {2391} INFO -  at 106.8s,\testimator xgboost's best error=0.3284,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:01] {2218} INFO - iteration 138, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:01] {2391} INFO -  at 107.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:01] {2218} INFO - iteration 139, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:02] {2391} INFO -  at 108.1s,\testimator xgboost's best error=0.3284,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:02] {2218} INFO - iteration 140, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:07] {2391} INFO -  at 112.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:07] {2218} INFO - iteration 141, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:09] {2391} INFO -  at 115.1s,\testimator xgboost's best error=0.3161,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:09] {2218} INFO - iteration 142, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:11] {2391} INFO -  at 116.5s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:11] {2218} INFO - iteration 143, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:12] {2391} INFO -  at 117.9s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:12] {2218} INFO - iteration 144, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:15] {2391} INFO -  at 120.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:15] {2218} INFO - iteration 145, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:15] {2391} INFO -  at 121.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:15] {2218} INFO - iteration 146, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:17] {2391} INFO -  at 122.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:17] {2218} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:18] {2391} INFO -  at 123.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:18] {2218} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:19] {2391} INFO -  at 124.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:19] {2218} INFO - iteration 149, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:19] {2391} INFO -  at 124.8s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:19] {2218} INFO - iteration 150, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:22] {2391} INFO -  at 127.6s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:22] {2218} INFO - iteration 151, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:22] {2391} INFO -  at 127.8s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:22] {2218} INFO - iteration 152, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:55:23] {2391} INFO -  at 128.5s,\testimator rf's best error=0.2967,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:23] {2218} INFO - iteration 153, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:24] {2391} INFO -  at 129.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:24] {2218} INFO - iteration 154, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:25] {2391} INFO -  at 130.5s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:25] {2218} INFO - iteration 155, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:25] {2391} INFO -  at 131.0s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:25] {2218} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:26] {2391} INFO -  at 132.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:26] {2218} INFO - iteration 157, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:27] {2391} INFO -  at 133.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:27] {2218} INFO - iteration 158, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:28] {2391} INFO -  at 134.3s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:28] {2218} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:29] {2391} INFO -  at 135.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:29] {2218} INFO - iteration 160, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:30] {2391} INFO -  at 135.7s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:30] {2218} INFO - iteration 161, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:30] {2391} INFO -  at 136.2s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:30] {2218} INFO - iteration 162, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:32] {2391} INFO -  at 137.9s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:32] {2218} INFO - iteration 163, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:34] {2391} INFO -  at 139.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:34] {2218} INFO - iteration 164, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:34] {2391} INFO -  at 139.8s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:34] {2218} INFO - iteration 165, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:35] {2391} INFO -  at 140.5s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:35] {2218} INFO - iteration 166, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:35] {2391} INFO -  at 140.9s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:35] {2218} INFO - iteration 167, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:36] {2391} INFO -  at 142.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:36] {2218} INFO - iteration 168, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:55:37] {2391} INFO -  at 142.7s,\testimator rf's best error=0.2967,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:37] {2218} INFO - iteration 169, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:38] {2391} INFO -  at 143.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:38] {2218} INFO - iteration 170, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:39] {2391} INFO -  at 144.8s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:39] {2218} INFO - iteration 171, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:39] {2391} INFO -  at 144.9s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:39] {2218} INFO - iteration 172, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:40] {2391} INFO -  at 146.1s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:40] {2218} INFO - iteration 173, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:42] {2391} INFO -  at 147.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:42] {2218} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:42] {2391} INFO -  at 148.4s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:42] {2218} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:43] {2391} INFO -  at 148.6s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:43] {2218} INFO - iteration 176, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:43] {2391} INFO -  at 149.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:43] {2218} INFO - iteration 177, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:44] {2391} INFO -  at 150.0s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:44] {2218} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:44] {2391} INFO -  at 150.3s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:44] {2218} INFO - iteration 179, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:46] {2391} INFO -  at 151.6s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:46] {2218} INFO - iteration 180, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:47] {2391} INFO -  at 152.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:47] {2218} INFO - iteration 181, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:47] {2391} INFO -  at 153.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:47] {2218} INFO - iteration 182, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:48] {2391} INFO -  at 154.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:48] {2218} INFO - iteration 183, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:49] {2391} INFO -  at 154.9s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:49] {2218} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:50] {2391} INFO -  at 155.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:50] {2218} INFO - iteration 185, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:50] {2391} INFO -  at 156.3s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:50] {2218} INFO - iteration 186, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:52] {2391} INFO -  at 157.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:52] {2218} INFO - iteration 187, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:53] {2391} INFO -  at 158.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:53] {2218} INFO - iteration 188, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:55] {2391} INFO -  at 160.6s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:55] {2218} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:56] {2391} INFO -  at 162.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:56] {2218} INFO - iteration 190, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:56] {2391} INFO -  at 162.4s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:56] {2218} INFO - iteration 191, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:58] {2391} INFO -  at 164.1s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:58] {2218} INFO - iteration 192, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:55:59] {2391} INFO -  at 164.4s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:59] {2218} INFO - iteration 193, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:55:59] {2391} INFO -  at 165.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:55:59] {2218} INFO - iteration 194, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:00] {2391} INFO -  at 165.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:00] {2218} INFO - iteration 195, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:00] {2391} INFO -  at 166.3s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:00] {2218} INFO - iteration 196, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:01] {2391} INFO -  at 167.3s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:01] {2218} INFO - iteration 197, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:02] {2391} INFO -  at 167.5s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:02] {2218} INFO - iteration 198, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:03] {2391} INFO -  at 168.6s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:03] {2218} INFO - iteration 199, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:03] {2391} INFO -  at 169.2s,\testimator rf's best error=0.2967,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:03] {2218} INFO - iteration 200, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:04] {2391} INFO -  at 170.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:04] {2218} INFO - iteration 201, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:05] {2391} INFO -  at 170.7s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:05] {2218} INFO - iteration 202, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:06] {2391} INFO -  at 172.2s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:06] {2218} INFO - iteration 203, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:07] {2391} INFO -  at 172.5s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:07] {2218} INFO - iteration 204, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:07] {2391} INFO -  at 173.1s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:07] {2218} INFO - iteration 205, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:08] {2391} INFO -  at 173.8s,\testimator xgboost's best error=0.2994,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:08] {2218} INFO - iteration 206, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:08] {2391} INFO -  at 174.1s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:08] {2218} INFO - iteration 207, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:09] {2391} INFO -  at 174.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:09] {2218} INFO - iteration 208, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:10] {2391} INFO -  at 175.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:10] {2218} INFO - iteration 209, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:10] {2391} INFO -  at 176.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:10] {2218} INFO - iteration 210, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:11] {2391} INFO -  at 176.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:11] {2218} INFO - iteration 211, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:11] {2391} INFO -  at 177.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:11] {2218} INFO - iteration 212, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:13] {2391} INFO -  at 179.1s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:13] {2218} INFO - iteration 213, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:14] {2391} INFO -  at 179.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:14] {2218} INFO - iteration 214, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:15] {2391} INFO -  at 180.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:15] {2218} INFO - iteration 215, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:17] {2391} INFO -  at 182.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:17] {2218} INFO - iteration 216, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:18] {2391} INFO -  at 183.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:18] {2218} INFO - iteration 217, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:18] {2391} INFO -  at 184.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:18] {2218} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:20] {2391} INFO -  at 186.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:20] {2218} INFO - iteration 219, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:21] {2391} INFO -  at 187.0s,\testimator rf's best error=0.2967,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:21] {2218} INFO - iteration 220, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:22] {2391} INFO -  at 187.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:22] {2218} INFO - iteration 221, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:24] {2391} INFO -  at 190.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:24] {2218} INFO - iteration 222, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:25] {2391} INFO -  at 190.6s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:25] {2218} INFO - iteration 223, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:25] {2391} INFO -  at 191.3s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:25] {2218} INFO - iteration 224, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:26] {2391} INFO -  at 191.9s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:26] {2218} INFO - iteration 225, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:26] {2391} INFO -  at 192.2s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:26] {2218} INFO - iteration 226, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:27] {2391} INFO -  at 192.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:27] {2218} INFO - iteration 227, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:27] {2391} INFO -  at 193.1s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:27] {2218} INFO - iteration 228, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:28] {2391} INFO -  at 193.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:28] {2218} INFO - iteration 229, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:28] {2391} INFO -  at 194.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:28] {2218} INFO - iteration 230, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:29] {2391} INFO -  at 194.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:29] {2218} INFO - iteration 231, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:30] {2391} INFO -  at 195.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:30] {2218} INFO - iteration 232, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:31] {2391} INFO -  at 197.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:31] {2218} INFO - iteration 233, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:32] {2391} INFO -  at 198.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:32] {2218} INFO - iteration 234, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:33] {2391} INFO -  at 198.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:33] {2218} INFO - iteration 235, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:34] {2391} INFO -  at 199.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:34] {2218} INFO - iteration 236, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:34] {2391} INFO -  at 199.9s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:34] {2218} INFO - iteration 237, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:36] {2391} INFO -  at 202.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:36] {2218} INFO - iteration 238, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:37] {2391} INFO -  at 203.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:37] {2218} INFO - iteration 239, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:38] {2391} INFO -  at 203.7s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:38] {2218} INFO - iteration 240, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:39] {2391} INFO -  at 204.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:39] {2218} INFO - iteration 241, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:39] {2391} INFO -  at 205.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:39] {2218} INFO - iteration 242, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:40] {2391} INFO -  at 205.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:40] {2218} INFO - iteration 243, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:41] {2391} INFO -  at 206.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:41] {2218} INFO - iteration 244, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:41] {2391} INFO -  at 207.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:41] {2218} INFO - iteration 245, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:42] {2391} INFO -  at 208.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:42] {2218} INFO - iteration 246, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:43] {2391} INFO -  at 208.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:43] {2218} INFO - iteration 247, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:43] {2391} INFO -  at 208.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:43] {2218} INFO - iteration 248, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:44] {2391} INFO -  at 209.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:44] {2218} INFO - iteration 249, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:44] {2391} INFO -  at 210.1s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:44] {2218} INFO - iteration 250, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:45] {2391} INFO -  at 211.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:45] {2218} INFO - iteration 251, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:46] {2391} INFO -  at 211.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:46] {2218} INFO - iteration 252, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:46] {2391} INFO -  at 212.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:46] {2218} INFO - iteration 253, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:47] {2391} INFO -  at 212.4s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:47] {2218} INFO - iteration 254, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:48] {2391} INFO -  at 213.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:48] {2218} INFO - iteration 255, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:48] {2391} INFO -  at 214.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:48] {2218} INFO - iteration 256, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:49] {2391} INFO -  at 214.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:49] {2218} INFO - iteration 257, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:49] {2391} INFO -  at 215.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:49] {2218} INFO - iteration 258, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:50] {2391} INFO -  at 215.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:50] {2218} INFO - iteration 259, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:51] {2391} INFO -  at 216.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:51] {2218} INFO - iteration 260, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:52] {2391} INFO -  at 217.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:52] {2218} INFO - iteration 261, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:56:52] {2391} INFO -  at 218.4s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:52] {2218} INFO - iteration 262, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:53] {2391} INFO -  at 219.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:53] {2218} INFO - iteration 263, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:54] {2391} INFO -  at 220.1s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:54] {2218} INFO - iteration 264, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:55] {2391} INFO -  at 220.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:55] {2218} INFO - iteration 265, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:57] {2391} INFO -  at 222.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:57] {2218} INFO - iteration 266, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:57] {2391} INFO -  at 222.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:57] {2218} INFO - iteration 267, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:57] {2391} INFO -  at 223.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:57] {2218} INFO - iteration 268, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:56:58] {2391} INFO -  at 224.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:58] {2218} INFO - iteration 269, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:56:59] {2391} INFO -  at 224.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:56:59] {2218} INFO - iteration 270, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:00] {2391} INFO -  at 225.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:00] {2218} INFO - iteration 271, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:02] {2391} INFO -  at 227.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:02] {2218} INFO - iteration 272, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:02] {2391} INFO -  at 228.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:02] {2218} INFO - iteration 273, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:03] {2391} INFO -  at 229.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:03] {2218} INFO - iteration 274, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:04] {2391} INFO -  at 229.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:04] {2218} INFO - iteration 275, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:04] {2391} INFO -  at 230.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:04] {2218} INFO - iteration 276, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:05] {2391} INFO -  at 230.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:05] {2218} INFO - iteration 277, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:05] {2391} INFO -  at 231.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:05] {2218} INFO - iteration 278, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:07] {2391} INFO -  at 232.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:07] {2218} INFO - iteration 279, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:07] {2391} INFO -  at 233.2s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:07] {2218} INFO - iteration 280, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:08] {2391} INFO -  at 234.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:08] {2218} INFO - iteration 281, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:09] {2391} INFO -  at 235.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:09] {2218} INFO - iteration 282, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:10] {2391} INFO -  at 235.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:10] {2218} INFO - iteration 283, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:10] {2391} INFO -  at 236.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:10] {2218} INFO - iteration 284, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:11] {2391} INFO -  at 236.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:11] {2218} INFO - iteration 285, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:11] {2391} INFO -  at 236.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:11] {2218} INFO - iteration 286, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:11] {2391} INFO -  at 237.1s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:11] {2218} INFO - iteration 287, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:12] {2391} INFO -  at 237.7s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:12] {2218} INFO - iteration 288, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:12] {2391} INFO -  at 238.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:12] {2218} INFO - iteration 289, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:13] {2391} INFO -  at 239.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:13] {2218} INFO - iteration 290, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:14] {2391} INFO -  at 239.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:14] {2218} INFO - iteration 291, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:14] {2391} INFO -  at 240.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:14] {2218} INFO - iteration 292, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:15] {2391} INFO -  at 240.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:15] {2218} INFO - iteration 293, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:16] {2391} INFO -  at 242.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:16] {2218} INFO - iteration 294, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:17] {2391} INFO -  at 242.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:17] {2218} INFO - iteration 295, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:18] {2391} INFO -  at 243.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:18] {2218} INFO - iteration 296, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:18] {2391} INFO -  at 244.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:18] {2218} INFO - iteration 297, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:20] {2391} INFO -  at 245.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:20] {2218} INFO - iteration 298, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:20] {2391} INFO -  at 246.2s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:20] {2218} INFO - iteration 299, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:21] {2391} INFO -  at 247.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:21] {2218} INFO - iteration 300, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:21] {2391} INFO -  at 247.4s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:21] {2218} INFO - iteration 301, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:22] {2391} INFO -  at 247.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:22] {2218} INFO - iteration 302, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:23] {2391} INFO -  at 248.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:23] {2218} INFO - iteration 303, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:23] {2391} INFO -  at 249.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:23] {2218} INFO - iteration 304, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:23] {2391} INFO -  at 249.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:23] {2218} INFO - iteration 305, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:24] {2391} INFO -  at 249.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:24] {2218} INFO - iteration 306, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:24] {2391} INFO -  at 250.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:24] {2218} INFO - iteration 307, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:25] {2391} INFO -  at 250.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:25] {2218} INFO - iteration 308, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:25] {2391} INFO -  at 251.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:25] {2218} INFO - iteration 309, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:26] {2391} INFO -  at 251.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:26] {2218} INFO - iteration 310, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:26] {2391} INFO -  at 252.3s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:26] {2218} INFO - iteration 311, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:28] {2391} INFO -  at 254.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:28] {2218} INFO - iteration 312, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:29] {2391} INFO -  at 255.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:29] {2218} INFO - iteration 313, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:29] {2391} INFO -  at 255.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:29] {2218} INFO - iteration 314, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:30] {2391} INFO -  at 255.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:30] {2218} INFO - iteration 315, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:30] {2391} INFO -  at 255.9s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:30] {2218} INFO - iteration 316, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:31] {2391} INFO -  at 256.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:31] {2218} INFO - iteration 317, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:31] {2391} INFO -  at 256.8s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:31] {2218} INFO - iteration 318, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:32] {2391} INFO -  at 257.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:32] {2218} INFO - iteration 319, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:32] {2391} INFO -  at 257.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:32] {2218} INFO - iteration 320, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:32] {2391} INFO -  at 258.4s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:33] {2218} INFO - iteration 321, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:33] {2391} INFO -  at 258.8s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:33] {2218} INFO - iteration 322, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:34] {2391} INFO -  at 259.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:34] {2218} INFO - iteration 323, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:35] {2391} INFO -  at 260.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:35] {2218} INFO - iteration 324, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:35] {2391} INFO -  at 260.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:35] {2218} INFO - iteration 325, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:36] {2391} INFO -  at 261.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:36] {2218} INFO - iteration 326, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:36] {2391} INFO -  at 262.0s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:36] {2218} INFO - iteration 327, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:37] {2391} INFO -  at 262.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:37] {2218} INFO - iteration 328, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:38] {2391} INFO -  at 263.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:38] {2218} INFO - iteration 329, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:38] {2391} INFO -  at 264.0s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:38] {2218} INFO - iteration 330, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:38] {2391} INFO -  at 264.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:38] {2218} INFO - iteration 331, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:39] {2391} INFO -  at 265.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:39] {2218} INFO - iteration 332, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:40] {2391} INFO -  at 265.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:40] {2218} INFO - iteration 333, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:40] {2391} INFO -  at 266.2s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:40] {2218} INFO - iteration 334, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:41] {2391} INFO -  at 266.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:41] {2218} INFO - iteration 335, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:41] {2391} INFO -  at 267.1s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:41] {2218} INFO - iteration 336, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:42] {2391} INFO -  at 267.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:42] {2218} INFO - iteration 337, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:42] {2391} INFO -  at 268.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:42] {2218} INFO - iteration 338, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:43] {2391} INFO -  at 268.8s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:43] {2218} INFO - iteration 339, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:44] {2391} INFO -  at 269.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:44] {2218} INFO - iteration 340, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:45] {2391} INFO -  at 270.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:45] {2218} INFO - iteration 341, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:45] {2391} INFO -  at 271.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:45] {2218} INFO - iteration 342, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:46] {2391} INFO -  at 271.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:46] {2218} INFO - iteration 343, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:47] {2391} INFO -  at 272.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:47] {2218} INFO - iteration 344, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:47] {2391} INFO -  at 272.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:47] {2218} INFO - iteration 345, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:48] {2391} INFO -  at 274.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:48] {2218} INFO - iteration 346, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:48] {2391} INFO -  at 274.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:48] {2218} INFO - iteration 347, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:49] {2391} INFO -  at 274.8s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:49] {2218} INFO - iteration 348, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:49] {2391} INFO -  at 275.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:49] {2218} INFO - iteration 349, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:50] {2391} INFO -  at 275.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:50] {2218} INFO - iteration 350, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:51] {2391} INFO -  at 276.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:51] {2218} INFO - iteration 351, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:51] {2391} INFO -  at 277.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:51] {2218} INFO - iteration 352, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:57:52] {2391} INFO -  at 277.4s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:52] {2218} INFO - iteration 353, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:53] {2391} INFO -  at 278.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:53] {2218} INFO - iteration 354, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:57:53] {2391} INFO -  at 279.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:53] {2218} INFO - iteration 355, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:54] {2391} INFO -  at 279.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:54] {2218} INFO - iteration 356, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:57:58] {2391} INFO -  at 283.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:57:58] {2218} INFO - iteration 357, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:01] {2391} INFO -  at 287.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:01] {2218} INFO - iteration 358, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:02] {2391} INFO -  at 287.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:02] {2218} INFO - iteration 359, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:02] {2391} INFO -  at 288.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:02] {2218} INFO - iteration 360, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:04] {2391} INFO -  at 289.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:04] {2218} INFO - iteration 361, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:04] {2391} INFO -  at 290.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:04] {2218} INFO - iteration 362, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:05] {2391} INFO -  at 290.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:05] {2218} INFO - iteration 363, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:06] {2391} INFO -  at 291.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:06] {2218} INFO - iteration 364, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:06] {2391} INFO -  at 291.9s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:06] {2218} INFO - iteration 365, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:07] {2391} INFO -  at 292.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:07] {2218} INFO - iteration 366, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:07] {2391} INFO -  at 293.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:07] {2218} INFO - iteration 367, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:08] {2391} INFO -  at 293.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:08] {2218} INFO - iteration 368, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:08] {2391} INFO -  at 294.1s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:08] {2218} INFO - iteration 369, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:11] {2391} INFO -  at 296.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:11] {2218} INFO - iteration 370, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:13] {2391} INFO -  at 298.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:13] {2218} INFO - iteration 371, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:15] {2391} INFO -  at 301.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:15] {2218} INFO - iteration 372, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:16] {2391} INFO -  at 301.5s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:16] {2218} INFO - iteration 373, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:16] {2391} INFO -  at 302.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:16] {2218} INFO - iteration 374, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:17] {2391} INFO -  at 302.9s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:17] {2218} INFO - iteration 375, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:17] {2391} INFO -  at 303.3s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:17] {2218} INFO - iteration 376, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:18] {2391} INFO -  at 303.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:18] {2218} INFO - iteration 377, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:18] {2391} INFO -  at 304.3s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:18] {2218} INFO - iteration 378, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:19] {2391} INFO -  at 305.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:19] {2218} INFO - iteration 379, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:21] {2391} INFO -  at 306.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:21] {2218} INFO - iteration 380, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:21] {2391} INFO -  at 307.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:21] {2218} INFO - iteration 381, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:22] {2391} INFO -  at 307.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:22] {2218} INFO - iteration 382, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:22] {2391} INFO -  at 307.9s,\testimator rf's best error=0.2953,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:22] {2218} INFO - iteration 383, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:23] {2391} INFO -  at 308.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:23] {2218} INFO - iteration 384, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:24] {2391} INFO -  at 309.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:24] {2218} INFO - iteration 385, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:25] {2391} INFO -  at 311.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:25] {2218} INFO - iteration 386, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:26] {2391} INFO -  at 311.7s,\testimator rf's best error=0.2952,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:26] {2218} INFO - iteration 387, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:26] {2391} INFO -  at 312.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:26] {2218} INFO - iteration 388, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:27] {2391} INFO -  at 313.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:27] {2218} INFO - iteration 389, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:28] {2391} INFO -  at 313.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:28] {2218} INFO - iteration 390, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:29] {2391} INFO -  at 314.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:29] {2218} INFO - iteration 391, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:29] {2391} INFO -  at 315.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:29] {2218} INFO - iteration 392, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:30] {2391} INFO -  at 316.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:30] {2218} INFO - iteration 393, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:31] {2391} INFO -  at 317.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:31] {2218} INFO - iteration 394, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:31] {2391} INFO -  at 317.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:31] {2218} INFO - iteration 395, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:32] {2391} INFO -  at 317.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:32] {2218} INFO - iteration 396, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:33] {2391} INFO -  at 318.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:33] {2218} INFO - iteration 397, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:33] {2391} INFO -  at 319.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:33] {2218} INFO - iteration 398, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:34] {2391} INFO -  at 320.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:34] {2218} INFO - iteration 399, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:35] {2391} INFO -  at 320.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:35] {2218} INFO - iteration 400, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:36] {2391} INFO -  at 321.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:36] {2218} INFO - iteration 401, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:36] {2391} INFO -  at 321.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:36] {2218} INFO - iteration 402, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:36] {2391} INFO -  at 321.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:36] {2218} INFO - iteration 403, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:37] {2391} INFO -  at 323.1s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:37] {2218} INFO - iteration 404, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:39] {2391} INFO -  at 324.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:39] {2218} INFO - iteration 405, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:40] {2391} INFO -  at 325.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:40] {2218} INFO - iteration 406, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:40] {2391} INFO -  at 326.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:40] {2218} INFO - iteration 407, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:41] {2391} INFO -  at 326.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:41] {2218} INFO - iteration 408, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:42] {2391} INFO -  at 327.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:42] {2218} INFO - iteration 409, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:43] {2391} INFO -  at 328.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:43] {2218} INFO - iteration 410, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:43] {2391} INFO -  at 329.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:43] {2218} INFO - iteration 411, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:44] {2391} INFO -  at 329.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:44] {2218} INFO - iteration 412, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:45] {2391} INFO -  at 330.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:45] {2218} INFO - iteration 413, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:46] {2391} INFO -  at 331.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:46] {2218} INFO - iteration 414, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:46] {2391} INFO -  at 331.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:46] {2218} INFO - iteration 415, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:46] {2391} INFO -  at 331.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:46] {2218} INFO - iteration 416, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:47] {2391} INFO -  at 332.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:47] {2218} INFO - iteration 417, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:47] {2391} INFO -  at 332.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:47] {2218} INFO - iteration 418, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:48] {2391} INFO -  at 333.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:48] {2218} INFO - iteration 419, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:48] {2391} INFO -  at 333.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:48] {2218} INFO - iteration 420, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:49] {2391} INFO -  at 334.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:49] {2218} INFO - iteration 421, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:50] {2391} INFO -  at 336.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:50] {2218} INFO - iteration 422, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:51] {2391} INFO -  at 336.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:51] {2218} INFO - iteration 423, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:52] {2391} INFO -  at 338.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:52] {2218} INFO - iteration 424, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:53] {2391} INFO -  at 338.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:53] {2218} INFO - iteration 425, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:53] {2391} INFO -  at 339.3s,\testimator rf's best error=0.2952,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:53] {2218} INFO - iteration 426, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:54] {2391} INFO -  at 339.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:54] {2218} INFO - iteration 427, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:55] {2391} INFO -  at 340.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:55] {2218} INFO - iteration 428, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:55] {2391} INFO -  at 341.1s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:55] {2218} INFO - iteration 429, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:58:56] {2391} INFO -  at 341.5s,\testimator rf's best error=0.2952,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:56] {2218} INFO - iteration 430, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:56] {2391} INFO -  at 341.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:56] {2218} INFO - iteration 431, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:57] {2391} INFO -  at 342.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:57] {2218} INFO - iteration 432, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:58:57] {2391} INFO -  at 343.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:57] {2218} INFO - iteration 433, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:58] {2391} INFO -  at 344.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:58] {2218} INFO - iteration 434, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:59] {2391} INFO -  at 344.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:59] {2218} INFO - iteration 435, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:58:59] {2391} INFO -  at 345.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:58:59] {2218} INFO - iteration 436, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:00] {2391} INFO -  at 346.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:00] {2218} INFO - iteration 437, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:01] {2391} INFO -  at 346.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:01] {2218} INFO - iteration 438, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:02] {2391} INFO -  at 347.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:02] {2218} INFO - iteration 439, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:02] {2391} INFO -  at 348.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:02] {2218} INFO - iteration 440, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:03] {2391} INFO -  at 348.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:03] {2218} INFO - iteration 441, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:04] {2391} INFO -  at 350.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:04] {2218} INFO - iteration 442, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:05] {2391} INFO -  at 350.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:05] {2218} INFO - iteration 443, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:05] {2391} INFO -  at 351.1s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:05] {2218} INFO - iteration 444, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:59:06] {2391} INFO -  at 351.6s,\testimator rf's best error=0.2952,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:06] {2218} INFO - iteration 445, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:06] {2391} INFO -  at 351.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:06] {2218} INFO - iteration 446, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:59:06] {2391} INFO -  at 352.4s,\testimator rf's best error=0.2952,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:06] {2218} INFO - iteration 447, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:07] {2391} INFO -  at 353.1s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:07] {2218} INFO - iteration 448, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:07] {2391} INFO -  at 353.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:07] {2218} INFO - iteration 449, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:09] {2391} INFO -  at 355.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:09] {2218} INFO - iteration 450, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:10] {2391} INFO -  at 355.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:10] {2218} INFO - iteration 451, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:11] {2391} INFO -  at 357.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:11] {2218} INFO - iteration 452, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:12] {2391} INFO -  at 358.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:12] {2218} INFO - iteration 453, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:13] {2391} INFO -  at 358.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:13] {2218} INFO - iteration 454, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:13] {2391} INFO -  at 359.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:13] {2218} INFO - iteration 455, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:13] {2391} INFO -  at 359.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:13] {2218} INFO - iteration 456, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:15] {2391} INFO -  at 361.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:15] {2218} INFO - iteration 457, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:17] {2391} INFO -  at 362.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:17] {2218} INFO - iteration 458, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:17] {2391} INFO -  at 362.6s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:17] {2218} INFO - iteration 459, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:17] {2391} INFO -  at 362.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:17] {2218} INFO - iteration 460, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:18] {2391} INFO -  at 363.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:18] {2218} INFO - iteration 461, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:18] {2391} INFO -  at 364.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:18] {2218} INFO - iteration 462, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:19] {2391} INFO -  at 364.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:19] {2218} INFO - iteration 463, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:19] {2391} INFO -  at 365.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:19] {2218} INFO - iteration 464, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:20] {2391} INFO -  at 365.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:20] {2218} INFO - iteration 465, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:20] {2391} INFO -  at 366.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:20] {2218} INFO - iteration 466, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:21] {2391} INFO -  at 367.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:21] {2218} INFO - iteration 467, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:22] {2391} INFO -  at 367.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:22] {2218} INFO - iteration 468, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:23] {2391} INFO -  at 368.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:23] {2218} INFO - iteration 469, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:23] {2391} INFO -  at 369.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:23] {2218} INFO - iteration 470, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:24] {2391} INFO -  at 370.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:24] {2218} INFO - iteration 471, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:25] {2391} INFO -  at 370.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:25] {2218} INFO - iteration 472, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:26] {2391} INFO -  at 371.5s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:26] {2218} INFO - iteration 473, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:26] {2391} INFO -  at 372.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:26] {2218} INFO - iteration 474, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:27] {2391} INFO -  at 373.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:27] {2218} INFO - iteration 475, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:28] {2391} INFO -  at 373.8s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:28] {2218} INFO - iteration 476, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:28] {2391} INFO -  at 374.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:28] {2218} INFO - iteration 477, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:30] {2391} INFO -  at 375.5s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:30] {2218} INFO - iteration 478, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:30] {2391} INFO -  at 376.3s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:30] {2218} INFO - iteration 479, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:31] {2391} INFO -  at 376.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:31] {2218} INFO - iteration 480, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:31] {2391} INFO -  at 377.1s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:31] {2218} INFO - iteration 481, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:59:32] {2391} INFO -  at 377.5s,\testimator rf's best error=0.2952,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:32] {2218} INFO - iteration 482, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:32] {2391} INFO -  at 377.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:32] {2218} INFO - iteration 483, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:32] {2391} INFO -  at 378.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:32] {2218} INFO - iteration 484, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:34] {2391} INFO -  at 379.9s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:34] {2218} INFO - iteration 485, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:34] {2391} INFO -  at 380.4s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:34] {2218} INFO - iteration 486, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:35] {2391} INFO -  at 380.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:35] {2218} INFO - iteration 487, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:35] {2391} INFO -  at 381.4s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:35] {2218} INFO - iteration 488, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:36] {2391} INFO -  at 381.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:36] {2218} INFO - iteration 489, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:37] {2391} INFO -  at 382.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:37] {2218} INFO - iteration 490, current learner rf\n",
      "[flaml.automl.logger: 02-06 12:59:37] {2391} INFO -  at 383.1s,\testimator rf's best error=0.2952,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:37] {2218} INFO - iteration 491, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:38] {2391} INFO -  at 383.7s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:38] {2218} INFO - iteration 492, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:38] {2391} INFO -  at 384.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:38] {2218} INFO - iteration 493, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:38] {2391} INFO -  at 384.3s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:38] {2218} INFO - iteration 494, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:39] {2391} INFO -  at 384.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:39] {2218} INFO - iteration 495, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:40] {2391} INFO -  at 386.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:40] {2218} INFO - iteration 496, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:41] {2391} INFO -  at 387.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:41] {2218} INFO - iteration 497, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:42] {2391} INFO -  at 388.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:42] {2218} INFO - iteration 498, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:42] {2391} INFO -  at 388.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:42] {2218} INFO - iteration 499, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:44] {2391} INFO -  at 390.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:44] {2218} INFO - iteration 500, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:46] {2391} INFO -  at 391.8s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:46] {2218} INFO - iteration 501, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:46] {2391} INFO -  at 392.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:46] {2218} INFO - iteration 502, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:47] {2391} INFO -  at 392.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:47] {2218} INFO - iteration 503, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:48] {2391} INFO -  at 393.6s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:48] {2218} INFO - iteration 504, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:48] {2391} INFO -  at 394.0s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:48] {2218} INFO - iteration 505, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:49] {2391} INFO -  at 394.7s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:49] {2218} INFO - iteration 506, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:49] {2391} INFO -  at 395.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:49] {2218} INFO - iteration 507, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:51] {2391} INFO -  at 397.0s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:51] {2218} INFO - iteration 508, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:52] {2391} INFO -  at 397.9s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:52] {2218} INFO - iteration 509, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:52] {2391} INFO -  at 398.2s,\testimator xgboost's best error=0.2936,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:52] {2218} INFO - iteration 510, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:53] {2391} INFO -  at 399.2s,\testimator lgbm's best error=0.2901,\tbest estimator lgbm's best error=0.2901\n",
      "[flaml.automl.logger: 02-06 12:59:53] {2218} INFO - iteration 511, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:54] {2391} INFO -  at 399.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 12:59:54] {2218} INFO - iteration 512, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:55] {2391} INFO -  at 400.6s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 12:59:55] {2218} INFO - iteration 513, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:55] {2391} INFO -  at 401.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 12:59:55] {2218} INFO - iteration 514, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:57] {2391} INFO -  at 402.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 12:59:57] {2218} INFO - iteration 515, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:58] {2391} INFO -  at 403.5s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 12:59:58] {2218} INFO - iteration 516, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 12:59:58] {2391} INFO -  at 404.1s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 12:59:58] {2218} INFO - iteration 517, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:58] {2391} INFO -  at 404.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 12:59:58] {2218} INFO - iteration 518, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 12:59:59] {2391} INFO -  at 405.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 12:59:59] {2218} INFO - iteration 519, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:00] {2391} INFO -  at 405.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:00] {2218} INFO - iteration 520, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:00] {2391} INFO -  at 406.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:00] {2218} INFO - iteration 521, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:01] {2391} INFO -  at 406.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:01] {2218} INFO - iteration 522, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:03] {2391} INFO -  at 408.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:03] {2218} INFO - iteration 523, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:04] {2391} INFO -  at 410.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:04] {2218} INFO - iteration 524, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:05] {2391} INFO -  at 410.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:05] {2218} INFO - iteration 525, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:05] {2391} INFO -  at 411.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:05] {2218} INFO - iteration 526, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:06] {2391} INFO -  at 411.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:06] {2218} INFO - iteration 527, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:06] {2391} INFO -  at 411.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:06] {2218} INFO - iteration 528, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:06] {2391} INFO -  at 412.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:06] {2218} INFO - iteration 529, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:07] {2391} INFO -  at 412.7s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:07] {2218} INFO - iteration 530, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:07] {2391} INFO -  at 413.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:07] {2218} INFO - iteration 531, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:08] {2391} INFO -  at 413.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:08] {2218} INFO - iteration 532, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:08] {2391} INFO -  at 413.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:08] {2218} INFO - iteration 533, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:09] {2391} INFO -  at 414.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:09] {2218} INFO - iteration 534, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:10] {2391} INFO -  at 416.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:10] {2218} INFO - iteration 535, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:11] {2391} INFO -  at 416.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:11] {2218} INFO - iteration 536, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:11] {2391} INFO -  at 417.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:11] {2218} INFO - iteration 537, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:11] {2391} INFO -  at 417.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:11] {2218} INFO - iteration 538, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:12] {2391} INFO -  at 418.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:12] {2218} INFO - iteration 539, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:13] {2391} INFO -  at 418.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:13] {2218} INFO - iteration 540, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:13] {2391} INFO -  at 419.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:13] {2218} INFO - iteration 541, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:00:14] {2391} INFO -  at 419.6s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:14] {2218} INFO - iteration 542, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:14] {2391} INFO -  at 419.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:14] {2218} INFO - iteration 543, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:15] {2391} INFO -  at 420.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:15] {2218} INFO - iteration 544, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:15] {2391} INFO -  at 421.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:15] {2218} INFO - iteration 545, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:16] {2391} INFO -  at 421.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:16] {2218} INFO - iteration 546, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:16] {2391} INFO -  at 422.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:16] {2218} INFO - iteration 547, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:17] {2391} INFO -  at 422.5s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:17] {2218} INFO - iteration 548, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:00:17] {2391} INFO -  at 423.1s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:17] {2218} INFO - iteration 549, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:18] {2391} INFO -  at 423.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:18] {2218} INFO - iteration 550, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:18] {2391} INFO -  at 424.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:18] {2218} INFO - iteration 551, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:18] {2391} INFO -  at 424.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:18] {2218} INFO - iteration 552, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:19] {2391} INFO -  at 425.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:19] {2218} INFO - iteration 553, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:20] {2391} INFO -  at 425.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:20] {2218} INFO - iteration 554, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:20] {2391} INFO -  at 426.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:20] {2218} INFO - iteration 555, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:21] {2391} INFO -  at 427.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:21] {2218} INFO - iteration 556, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:21] {2391} INFO -  at 427.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:21] {2218} INFO - iteration 557, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:22] {2391} INFO -  at 427.7s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:22] {2218} INFO - iteration 558, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:22] {2391} INFO -  at 428.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:22] {2218} INFO - iteration 559, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:23] {2391} INFO -  at 428.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:23] {2218} INFO - iteration 560, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:23] {2391} INFO -  at 428.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:23] {2218} INFO - iteration 561, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:24] {2391} INFO -  at 429.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:24] {2218} INFO - iteration 562, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:25] {2391} INFO -  at 431.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:25] {2218} INFO - iteration 563, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:26] {2391} INFO -  at 432.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:26] {2218} INFO - iteration 564, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:26] {2391} INFO -  at 432.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:26] {2218} INFO - iteration 565, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:27] {2391} INFO -  at 432.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:27] {2218} INFO - iteration 566, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:00:27] {2391} INFO -  at 433.1s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:27] {2218} INFO - iteration 567, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:28] {2391} INFO -  at 433.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:28] {2218} INFO - iteration 568, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:28] {2391} INFO -  at 434.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:28] {2218} INFO - iteration 569, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:30] {2391} INFO -  at 435.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:30] {2218} INFO - iteration 570, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:30] {2391} INFO -  at 435.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:30] {2218} INFO - iteration 571, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:30] {2391} INFO -  at 436.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:30] {2218} INFO - iteration 572, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:00:31] {2391} INFO -  at 436.8s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:31] {2218} INFO - iteration 573, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:31] {2391} INFO -  at 437.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:31] {2218} INFO - iteration 574, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:31] {2391} INFO -  at 437.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:31] {2218} INFO - iteration 575, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:32] {2391} INFO -  at 437.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:32] {2218} INFO - iteration 576, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:33] {2391} INFO -  at 439.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:33] {2218} INFO - iteration 577, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:33] {2391} INFO -  at 439.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:33] {2218} INFO - iteration 578, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:35] {2391} INFO -  at 441.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:35] {2218} INFO - iteration 579, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:36] {2391} INFO -  at 441.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:36] {2218} INFO - iteration 580, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:36] {2391} INFO -  at 442.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:36] {2218} INFO - iteration 581, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:37] {2391} INFO -  at 442.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:37] {2218} INFO - iteration 582, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:37] {2391} INFO -  at 442.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:37] {2218} INFO - iteration 583, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:39] {2391} INFO -  at 444.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:39] {2218} INFO - iteration 584, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:39] {2391} INFO -  at 445.4s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:39] {2218} INFO - iteration 585, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:40] {2391} INFO -  at 446.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:40] {2218} INFO - iteration 586, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:40] {2391} INFO -  at 446.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:40] {2218} INFO - iteration 587, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:41] {2391} INFO -  at 446.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:41] {2218} INFO - iteration 588, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:42] {2391} INFO -  at 447.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:42] {2218} INFO - iteration 589, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:42] {2391} INFO -  at 448.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:42] {2218} INFO - iteration 590, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:43] {2391} INFO -  at 448.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:43] {2218} INFO - iteration 591, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:44] {2391} INFO -  at 449.9s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:44] {2218} INFO - iteration 592, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:44] {2391} INFO -  at 450.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:44] {2218} INFO - iteration 593, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:45] {2391} INFO -  at 450.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:45] {2218} INFO - iteration 594, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:45] {2391} INFO -  at 451.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:45] {2218} INFO - iteration 595, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:46] {2391} INFO -  at 451.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:46] {2218} INFO - iteration 596, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:46] {2391} INFO -  at 452.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:46] {2218} INFO - iteration 597, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:47] {2391} INFO -  at 452.6s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:47] {2218} INFO - iteration 598, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:48] {2391} INFO -  at 454.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:48] {2218} INFO - iteration 599, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:49] {2391} INFO -  at 455.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:49] {2218} INFO - iteration 600, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:49] {2391} INFO -  at 455.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:49] {2218} INFO - iteration 601, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:50] {2391} INFO -  at 455.9s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:50] {2218} INFO - iteration 602, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:51] {2391} INFO -  at 457.1s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:51] {2218} INFO - iteration 603, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:52] {2391} INFO -  at 458.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:52] {2218} INFO - iteration 604, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:53] {2391} INFO -  at 458.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:53] {2218} INFO - iteration 605, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:53] {2391} INFO -  at 459.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:53] {2218} INFO - iteration 606, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:54] {2391} INFO -  at 459.7s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:54] {2218} INFO - iteration 607, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:54] {2391} INFO -  at 460.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:54] {2218} INFO - iteration 608, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:55] {2391} INFO -  at 460.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:55] {2218} INFO - iteration 609, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:55] {2391} INFO -  at 460.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:55] {2218} INFO - iteration 610, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:55] {2391} INFO -  at 461.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:55] {2218} INFO - iteration 611, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:57] {2391} INFO -  at 462.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:57] {2218} INFO - iteration 612, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:57] {2391} INFO -  at 463.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:57] {2218} INFO - iteration 613, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:57] {2391} INFO -  at 463.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:57] {2218} INFO - iteration 614, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:58] {2391} INFO -  at 463.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:58] {2218} INFO - iteration 615, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:58] {2391} INFO -  at 464.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:58] {2218} INFO - iteration 616, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:00:59] {2391} INFO -  at 464.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:59] {2218} INFO - iteration 617, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:00:59] {2391} INFO -  at 465.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:00:59] {2218} INFO - iteration 618, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:00] {2391} INFO -  at 466.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:00] {2218} INFO - iteration 619, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:01] {2391} INFO -  at 467.1s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:01] {2218} INFO - iteration 620, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:02] {2391} INFO -  at 467.9s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:02] {2218} INFO - iteration 621, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:02] {2391} INFO -  at 468.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:02] {2218} INFO - iteration 622, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:02] {2391} INFO -  at 468.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:02] {2218} INFO - iteration 623, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:03] {2391} INFO -  at 469.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:03] {2218} INFO - iteration 624, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:05] {2391} INFO -  at 471.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:05] {2218} INFO - iteration 625, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:06] {2391} INFO -  at 472.4s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:06] {2218} INFO - iteration 626, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:07] {2391} INFO -  at 472.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:07] {2218} INFO - iteration 627, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:08] {2391} INFO -  at 473.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:08] {2218} INFO - iteration 628, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:08] {2391} INFO -  at 474.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:08] {2218} INFO - iteration 629, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:09] {2391} INFO -  at 475.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:09] {2218} INFO - iteration 630, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:10] {2391} INFO -  at 475.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:10] {2218} INFO - iteration 631, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:10] {2391} INFO -  at 475.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:10] {2218} INFO - iteration 632, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:12] {2391} INFO -  at 477.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:12] {2218} INFO - iteration 633, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:14] {2391} INFO -  at 479.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:14] {2218} INFO - iteration 634, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:14] {2391} INFO -  at 479.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:14] {2218} INFO - iteration 635, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:14] {2391} INFO -  at 480.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:14] {2218} INFO - iteration 636, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:15] {2391} INFO -  at 480.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:15] {2218} INFO - iteration 637, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:17] {2391} INFO -  at 482.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:17] {2218} INFO - iteration 638, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:17] {2391} INFO -  at 483.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:17] {2218} INFO - iteration 639, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:18] {2391} INFO -  at 483.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:18] {2218} INFO - iteration 640, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:18] {2391} INFO -  at 484.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:18] {2218} INFO - iteration 641, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:19] {2391} INFO -  at 485.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:19] {2218} INFO - iteration 642, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:20] {2391} INFO -  at 485.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:20] {2218} INFO - iteration 643, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:21] {2391} INFO -  at 486.9s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:21] {2218} INFO - iteration 644, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:21] {2391} INFO -  at 487.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:21] {2218} INFO - iteration 645, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:22] {2391} INFO -  at 488.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:22] {2218} INFO - iteration 646, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:23] {2391} INFO -  at 488.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:23] {2218} INFO - iteration 647, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:24] {2391} INFO -  at 489.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:24] {2218} INFO - iteration 648, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:25] {2391} INFO -  at 490.5s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:25] {2218} INFO - iteration 649, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:26] {2391} INFO -  at 491.6s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:26] {2218} INFO - iteration 650, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:27] {2391} INFO -  at 492.6s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:27] {2218} INFO - iteration 651, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:27] {2391} INFO -  at 493.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:27] {2218} INFO - iteration 652, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:27] {2391} INFO -  at 493.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:27] {2218} INFO - iteration 653, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:28] {2391} INFO -  at 493.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:28] {2218} INFO - iteration 654, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:29] {2391} INFO -  at 495.4s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:29] {2218} INFO - iteration 655, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:30] {2391} INFO -  at 496.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:30] {2218} INFO - iteration 656, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:31] {2391} INFO -  at 496.6s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:31] {2218} INFO - iteration 657, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:32] {2391} INFO -  at 497.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:32] {2218} INFO - iteration 658, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:33] {2391} INFO -  at 499.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:33] {2218} INFO - iteration 659, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:34] {2391} INFO -  at 499.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:34] {2218} INFO - iteration 660, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:35] {2391} INFO -  at 500.5s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:35] {2218} INFO - iteration 661, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:35] {2391} INFO -  at 500.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:35] {2218} INFO - iteration 662, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:35] {2391} INFO -  at 501.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:35] {2218} INFO - iteration 663, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:36] {2391} INFO -  at 501.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:36] {2218} INFO - iteration 664, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:36] {2391} INFO -  at 501.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:36] {2218} INFO - iteration 665, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:37] {2391} INFO -  at 503.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:37] {2218} INFO - iteration 666, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:38] {2391} INFO -  at 503.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:38] {2218} INFO - iteration 667, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:38] {2391} INFO -  at 504.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:38] {2218} INFO - iteration 668, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:39] {2391} INFO -  at 504.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:39] {2218} INFO - iteration 669, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:39] {2391} INFO -  at 505.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:39] {2218} INFO - iteration 670, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:40] {2391} INFO -  at 506.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:40] {2218} INFO - iteration 671, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:41] {2391} INFO -  at 506.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:41] {2218} INFO - iteration 672, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:42] {2391} INFO -  at 507.7s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:42] {2218} INFO - iteration 673, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:42] {2391} INFO -  at 508.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:42] {2218} INFO - iteration 674, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:44] {2391} INFO -  at 510.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:44] {2218} INFO - iteration 675, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:45] {2391} INFO -  at 510.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:45] {2218} INFO - iteration 676, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:46] {2391} INFO -  at 511.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:46] {2218} INFO - iteration 677, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:46] {2391} INFO -  at 511.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:46] {2218} INFO - iteration 678, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:47] {2391} INFO -  at 512.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:47] {2218} INFO - iteration 679, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:47] {2391} INFO -  at 512.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:47] {2218} INFO - iteration 680, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:01:47] {2391} INFO -  at 513.2s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:47] {2218} INFO - iteration 681, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:48] {2391} INFO -  at 513.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:48] {2218} INFO - iteration 682, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:48] {2391} INFO -  at 513.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:48] {2218} INFO - iteration 683, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:49] {2391} INFO -  at 514.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:49] {2218} INFO - iteration 684, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:49] {2391} INFO -  at 514.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:49] {2218} INFO - iteration 685, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:49] {2391} INFO -  at 515.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:49] {2218} INFO - iteration 686, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:50] {2391} INFO -  at 515.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:50] {2218} INFO - iteration 687, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:50] {2391} INFO -  at 515.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:50] {2218} INFO - iteration 688, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:52] {2391} INFO -  at 517.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:52] {2218} INFO - iteration 689, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:52] {2391} INFO -  at 518.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:52] {2218} INFO - iteration 690, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:54] {2391} INFO -  at 519.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:54] {2218} INFO - iteration 691, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:54] {2391} INFO -  at 520.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:54] {2218} INFO - iteration 692, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:55] {2391} INFO -  at 520.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:55] {2218} INFO - iteration 693, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:01:55] {2391} INFO -  at 521.0s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:55] {2218} INFO - iteration 694, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:55] {2391} INFO -  at 521.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:55] {2218} INFO - iteration 695, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:58] {2391} INFO -  at 523.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:58] {2218} INFO - iteration 696, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:01:58] {2391} INFO -  at 524.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:58] {2218} INFO - iteration 697, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:01:59] {2391} INFO -  at 525.4s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:01:59] {2218} INFO - iteration 698, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:00] {2391} INFO -  at 525.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:00] {2218} INFO - iteration 699, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:01] {2391} INFO -  at 526.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:01] {2218} INFO - iteration 700, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:01] {2391} INFO -  at 526.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:01] {2218} INFO - iteration 701, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:01] {2391} INFO -  at 527.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:01] {2218} INFO - iteration 702, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:02] {2391} INFO -  at 527.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:02] {2218} INFO - iteration 703, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:02] {2391} INFO -  at 528.4s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:02] {2218} INFO - iteration 704, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:03] {2391} INFO -  at 529.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:03] {2218} INFO - iteration 705, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:03] {2391} INFO -  at 529.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:03] {2218} INFO - iteration 706, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:04] {2391} INFO -  at 530.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:04] {2218} INFO - iteration 707, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:04] {2391} INFO -  at 530.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:04] {2218} INFO - iteration 708, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:06] {2391} INFO -  at 531.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:06] {2218} INFO - iteration 709, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:06] {2391} INFO -  at 531.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:06] {2218} INFO - iteration 710, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:07] {2391} INFO -  at 532.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:07] {2218} INFO - iteration 711, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:07] {2391} INFO -  at 532.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:07] {2218} INFO - iteration 712, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:07] {2391} INFO -  at 533.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:07] {2218} INFO - iteration 713, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:08] {2391} INFO -  at 533.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:08] {2218} INFO - iteration 714, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:08] {2391} INFO -  at 533.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:08] {2218} INFO - iteration 715, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:08] {2391} INFO -  at 534.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:08] {2218} INFO - iteration 716, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:09] {2391} INFO -  at 535.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:09] {2218} INFO - iteration 717, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:10] {2391} INFO -  at 535.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:10] {2218} INFO - iteration 718, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:10] {2391} INFO -  at 536.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:10] {2218} INFO - iteration 719, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:10] {2391} INFO -  at 536.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:10] {2218} INFO - iteration 720, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:12] {2391} INFO -  at 537.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:12] {2218} INFO - iteration 721, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:12] {2391} INFO -  at 537.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:12] {2218} INFO - iteration 722, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:12] {2391} INFO -  at 538.4s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:12] {2218} INFO - iteration 723, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:13] {2391} INFO -  at 538.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:13] {2218} INFO - iteration 724, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:15] {2391} INFO -  at 541.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:15] {2218} INFO - iteration 725, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:15] {2391} INFO -  at 541.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:15] {2218} INFO - iteration 726, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:17] {2391} INFO -  at 542.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:17] {2218} INFO - iteration 727, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:17] {2391} INFO -  at 543.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:17] {2218} INFO - iteration 728, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:18] {2391} INFO -  at 543.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:18] {2218} INFO - iteration 729, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:19] {2391} INFO -  at 544.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:19] {2218} INFO - iteration 730, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:20] {2391} INFO -  at 545.6s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:20] {2218} INFO - iteration 731, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:20] {2391} INFO -  at 546.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:20] {2218} INFO - iteration 732, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:20] {2391} INFO -  at 546.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:20] {2218} INFO - iteration 733, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:22] {2391} INFO -  at 547.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:22] {2218} INFO - iteration 734, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:22] {2391} INFO -  at 548.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:22] {2218} INFO - iteration 735, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:23] {2391} INFO -  at 548.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:23] {2218} INFO - iteration 736, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:24] {2391} INFO -  at 549.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:24] {2218} INFO - iteration 737, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:24] {2391} INFO -  at 550.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:24] {2218} INFO - iteration 738, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:26] {2391} INFO -  at 551.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:26] {2218} INFO - iteration 739, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:26] {2391} INFO -  at 551.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:26] {2218} INFO - iteration 740, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:27] {2391} INFO -  at 552.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:27] {2218} INFO - iteration 741, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:27] {2391} INFO -  at 553.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:27] {2218} INFO - iteration 742, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:02:28] {2391} INFO -  at 553.8s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:28] {2218} INFO - iteration 743, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:28] {2391} INFO -  at 554.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:28] {2218} INFO - iteration 744, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:29] {2391} INFO -  at 554.8s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:29] {2218} INFO - iteration 745, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:29] {2391} INFO -  at 555.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:29] {2218} INFO - iteration 746, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:30] {2391} INFO -  at 555.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:30] {2218} INFO - iteration 747, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:02:30] {2391} INFO -  at 556.2s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:30] {2218} INFO - iteration 748, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:31] {2391} INFO -  at 556.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:31] {2218} INFO - iteration 749, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:31] {2391} INFO -  at 557.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:31] {2218} INFO - iteration 750, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:31] {2391} INFO -  at 557.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:31] {2218} INFO - iteration 751, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:32] {2391} INFO -  at 558.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:32] {2218} INFO - iteration 752, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:33] {2391} INFO -  at 558.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:33] {2218} INFO - iteration 753, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:33] {2391} INFO -  at 559.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:33] {2218} INFO - iteration 754, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:34] {2391} INFO -  at 559.8s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:34] {2218} INFO - iteration 755, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:34] {2391} INFO -  at 560.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:34] {2218} INFO - iteration 756, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:35] {2391} INFO -  at 560.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:35] {2218} INFO - iteration 757, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:35] {2391} INFO -  at 561.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:35] {2218} INFO - iteration 758, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:36] {2391} INFO -  at 562.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:36] {2218} INFO - iteration 759, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:37] {2391} INFO -  at 562.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:37] {2218} INFO - iteration 760, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:37] {2391} INFO -  at 563.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:37] {2218} INFO - iteration 761, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:38] {2391} INFO -  at 563.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:38] {2218} INFO - iteration 762, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:38] {2391} INFO -  at 563.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:38] {2218} INFO - iteration 763, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:39] {2391} INFO -  at 564.9s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:39] {2218} INFO - iteration 764, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:39] {2391} INFO -  at 565.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:39] {2218} INFO - iteration 765, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:40] {2391} INFO -  at 565.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:40] {2218} INFO - iteration 766, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:40] {2391} INFO -  at 566.3s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:40] {2218} INFO - iteration 767, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:41] {2391} INFO -  at 567.1s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:41] {2218} INFO - iteration 768, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:02:42] {2391} INFO -  at 567.6s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:42] {2218} INFO - iteration 769, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:42] {2391} INFO -  at 567.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:42] {2218} INFO - iteration 770, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:44] {2391} INFO -  at 569.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:44] {2218} INFO - iteration 771, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:44] {2391} INFO -  at 570.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:44] {2218} INFO - iteration 772, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:45] {2391} INFO -  at 570.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:45] {2218} INFO - iteration 773, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:46] {2391} INFO -  at 571.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:46] {2218} INFO - iteration 774, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:46] {2391} INFO -  at 571.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:46] {2218} INFO - iteration 775, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:46] {2391} INFO -  at 572.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:46] {2218} INFO - iteration 776, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:47] {2391} INFO -  at 572.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:47] {2218} INFO - iteration 777, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:47] {2391} INFO -  at 573.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:47] {2218} INFO - iteration 778, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:48] {2391} INFO -  at 573.6s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:48] {2218} INFO - iteration 779, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:49] {2391} INFO -  at 574.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:49] {2218} INFO - iteration 780, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:50] {2391} INFO -  at 576.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:50] {2218} INFO - iteration 781, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:51] {2391} INFO -  at 577.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:51] {2218} INFO - iteration 782, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:52] {2391} INFO -  at 577.7s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:52] {2218} INFO - iteration 783, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:52] {2391} INFO -  at 578.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:52] {2218} INFO - iteration 784, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:52] {2391} INFO -  at 578.2s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:52] {2218} INFO - iteration 785, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:53] {2391} INFO -  at 578.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:53] {2218} INFO - iteration 786, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:53] {2391} INFO -  at 578.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:53] {2218} INFO - iteration 787, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:53] {2391} INFO -  at 579.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:53] {2218} INFO - iteration 788, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:55] {2391} INFO -  at 580.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:55] {2218} INFO - iteration 789, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:55] {2391} INFO -  at 580.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:55] {2218} INFO - iteration 790, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:55] {2391} INFO -  at 581.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:55] {2218} INFO - iteration 791, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:02:56] {2391} INFO -  at 582.0s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:56] {2218} INFO - iteration 792, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:57] {2391} INFO -  at 582.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:57] {2218} INFO - iteration 793, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:57] {2391} INFO -  at 583.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:57] {2218} INFO - iteration 794, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:58] {2391} INFO -  at 584.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:58] {2218} INFO - iteration 795, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:02:59] {2391} INFO -  at 584.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:02:59] {2218} INFO - iteration 796, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:00] {2391} INFO -  at 585.6s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:00] {2218} INFO - iteration 797, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:03:00] {2391} INFO -  at 586.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:00] {2218} INFO - iteration 798, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:02] {2391} INFO -  at 587.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:02] {2218} INFO - iteration 799, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:02] {2391} INFO -  at 587.7s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:02] {2218} INFO - iteration 800, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:02] {2391} INFO -  at 588.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:02] {2218} INFO - iteration 801, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:03] {2391} INFO -  at 588.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:03] {2218} INFO - iteration 802, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:03] {2391} INFO -  at 588.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:03] {2218} INFO - iteration 803, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:03] {2391} INFO -  at 589.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:03] {2218} INFO - iteration 804, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:03:04] {2391} INFO -  at 589.7s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:04] {2218} INFO - iteration 805, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:04] {2391} INFO -  at 590.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:04] {2218} INFO - iteration 806, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:05] {2391} INFO -  at 591.1s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:05] {2218} INFO - iteration 807, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:06] {2391} INFO -  at 591.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:06] {2218} INFO - iteration 808, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:06] {2391} INFO -  at 592.0s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:06] {2218} INFO - iteration 809, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:03:07] {2391} INFO -  at 593.1s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:07] {2218} INFO - iteration 810, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:09] {2391} INFO -  at 594.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:09] {2218} INFO - iteration 811, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:10] {2391} INFO -  at 595.4s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:10] {2218} INFO - iteration 812, current learner lgbm\n",
      "[flaml.automl.logger: 02-06 13:03:10] {2391} INFO -  at 596.2s,\testimator lgbm's best error=0.2901,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:10] {2218} INFO - iteration 813, current learner rf\n",
      "[flaml.automl.logger: 02-06 13:03:11] {2391} INFO -  at 596.6s,\testimator rf's best error=0.2952,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:11] {2218} INFO - iteration 814, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:11] {2391} INFO -  at 596.9s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:11] {2218} INFO - iteration 815, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:11] {2391} INFO -  at 597.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:11] {2218} INFO - iteration 816, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:12] {2391} INFO -  at 598.3s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:12] {2218} INFO - iteration 817, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:13] {2391} INFO -  at 598.5s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:13] {2218} INFO - iteration 818, current learner xgboost\n",
      "[flaml.automl.logger: 02-06 13:03:14] {2391} INFO -  at 599.8s,\testimator xgboost's best error=0.2848,\tbest estimator xgboost's best error=0.2848\n",
      "[flaml.automl.logger: 02-06 13:03:14] {2627} INFO - retrain xgboost for 0.1s\n",
      "[flaml.automl.logger: 02-06 13:03:14] {2630} INFO - retrained model: XGBClassifier(base_score=None, booster=None, callbacks=[],\n",
      "              colsample_bylevel=0.8132362227279891, colsample_bynode=None,\n",
      "              colsample_bytree=0.9908672495580634, device=None,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, feature_types=None, gamma=None,\n",
      "              grow_policy='lossguide', importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.43080693142586285,\n",
      "              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=0, max_leaves=22,\n",
      "              min_child_weight=28.595734174457895, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=4,\n",
      "              n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 02-06 13:03:14] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 02-06 13:03:14] {1931} INFO - Time taken to find the best model: 399.7056052684784\n"
     ]
    }
   ],
   "source": [
    "# train and save final models, temptatively\n",
    "import lazyqsar as lq\n",
    "\n",
    "train_set = pd.read_csv(os.path.join(DATAPATH, \"training_set_clean.csv\"))\n",
    "X_train = train_set[\"smiles\"]\n",
    "y_train = train_set[\"outcome\"]\n",
    "\n",
    "# Fit the model on the training set\n",
    "model = lq.ErsiliaBinaryClassifier(time_budget_sec=600, estimator_list=[\"rf\", \"lgbm\", \"xgboost\"])\n",
    "model.fit(X_train, y_train)\n",
    "model.save(os.path.join(MODELPATH, \"ersilia_lq.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240206_123841\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240206_123841/ds_sub_fit/sub_fit_ho.\n",
      "Beginning AutoGluon training ... Time limit = 150s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240206_123841/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #15~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Jan 12 18:54:30 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       54.28 GB / 62.35 GB (87.1%)\n",
      "Disk Space Avail:   585.30 GB / 915.32 GB (63.9%)\n",
      "===================================================\n",
      "Train Data Rows:    518\n",
      "Train Data Columns: 1024\n",
      "Label Column:       outcome\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    55589.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['eosce_0', 'eosce_1', 'eosce_2', 'eosce_3', 'eosce_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['eosce_0', 'eosce_1', 'eosce_2', 'eosce_3', 'eosce_4', ...]\n",
      "\t1.7s = Fit runtime\n",
      "\t1024 features in original data used to generate 1024 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.74s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 98.82s of the 148.25s of remaining time.\n",
      "\t0.6525\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 98.63s of the 148.06s of remaining time.\n",
      "\t0.6525\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 98.46s of the 147.9s of remaining time.\n",
      "Will use sequential fold fitting strategy because import of ray failed. Reason: ray==2.9.1 detected. 2.6.3 <= ray < 2.7.0 is required. You can use pip to install certain version of ray `pip install ray==2.6.3` \n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7471\t = Validation score   (accuracy)\n",
      "\t6.73s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 91.52s of the 140.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7529\t = Validation score   (accuracy)\n",
      "\t12.12s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 79.2s of the 128.63s of remaining time.\n",
      "\t0.7046\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 78.49s of the 127.93s of remaining time.\n",
      "\t0.6815\t = Validation score   (accuracy)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 77.82s of the 127.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 238.\n",
      "\tRan out of time, early stopping on iteration 248.\n",
      "\tRan out of time, early stopping on iteration 240.\n",
      "\tRan out of time, early stopping on iteration 262.\n",
      "\tRan out of time, early stopping on iteration 275.\n",
      "\tRan out of time, early stopping on iteration 294.\n",
      "\tRan out of time, early stopping on iteration 317.\n",
      "\t0.7413\t = Validation score   (accuracy)\n",
      "\t72.47s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 5.06s of the 54.5s of remaining time.\n",
      "\t0.6892\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4.11s of the 53.54s of remaining time.\n",
      "\t0.6834\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3.24s of the 52.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 2.62s of the 52.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L1.\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2.03s of the 51.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1.58s of the 51.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.338462\n",
      "\tTime limit exceeded... Skipping LightGBMLarge_BAG_L1.\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1.09s of the 50.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_r177_BAG_L1.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 0.61s of the 50.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 0.13s of the 49.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.338462\n",
      "\tTime limit exceeded... Skipping LightGBM_r131_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 148.26s of the 48.75s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.7529\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 48.49s of the 48.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.749\t = Validation score   (accuracy)\n",
      "\t6.74s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 41.53s of the 41.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7529\t = Validation score   (accuracy)\n",
      "\t11.49s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 29.85s of the 29.82s of remaining time.\n",
      "\t0.7143\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 29.14s of the 29.11s of remaining time.\n",
      "\t0.7143\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 28.47s of the 28.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 84.\n",
      "\tRan out of time, early stopping on iteration 88.\n",
      "\tRan out of time, early stopping on iteration 90.\n",
      "\tRan out of time, early stopping on iteration 94.\n",
      "\tRan out of time, early stopping on iteration 88.\n",
      "\tRan out of time, early stopping on iteration 102.\n",
      "\tRan out of time, early stopping on iteration 113.\n",
      "\tRan out of time, early stopping on iteration 131.\n",
      "\t0.7548\t = Validation score   (accuracy)\n",
      "\t27.07s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 148.26s of the -0.68s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.917, 'LightGBMXT_BAG_L1': 0.056, 'LightGBMXT_BAG_L2': 0.028}\n",
      "\t0.7606\t = Validation score   (accuracy)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 151.07s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240206_123841/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                      model  holdout_score  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     ExtraTreesGini_BAG_L1       0.830769   0.689189    accuracy        0.025897       0.093517    0.776570                 0.025897                0.093517           0.776570            1       True          8\n",
      "1           CatBoost_BAG_L1       0.830769   0.741313    accuracy        0.082428       0.150411   72.468344                 0.082428                0.150411          72.468344            1       True          7\n",
      "2   RandomForestEntr_BAG_L2       0.830769   0.714286    accuracy        0.411833       0.762313   94.412335                 0.052283                0.093426           0.484835            2       True         14\n",
      "3   RandomForestEntr_BAG_L1       0.815385   0.681467    accuracy        0.053795       0.084756    0.504128                 0.053795                0.084756           0.504128            1       True          6\n",
      "4           CatBoost_BAG_L2       0.815385   0.754826    accuracy        0.443979       0.944377  120.992961                 0.084429                0.275490          27.065461            2       True         15\n",
      "5         LightGBMXT_BAG_L2       0.815385   0.749035    accuracy        0.447162       0.711262  100.663545                 0.087613                0.042374           6.736045            2       True         11\n",
      "6       WeightedEnsemble_L3       0.815385   0.760618    accuracy        0.532849       0.987569  128.110375                 0.001257                0.000818           0.381368            3       True         16\n",
      "7           LightGBM_BAG_L1       0.800000   0.752896    accuracy        0.017608       0.029238   12.116441                 0.017608                0.029238          12.116441            1       True          4\n",
      "8       WeightedEnsemble_L2       0.800000   0.752896    accuracy        0.020345       0.030048   12.363510                 0.002737                0.000810           0.247068            2       True         10\n",
      "9     ExtraTreesEntr_BAG_L1       0.800000   0.683398    accuracy        0.039453       0.090341    0.700712                 0.039453                0.090341           0.700712            1       True          9\n",
      "10        LightGBMXT_BAG_L1       0.800000   0.747104    accuracy        0.071589       0.035964    6.732606                 0.071589                0.035964           6.732606            1       True          3\n",
      "11  RandomForestGini_BAG_L2       0.800000   0.714286    accuracy        0.416992       0.756859   94.452535                 0.057442                0.087971           0.525036            2       True         13\n",
      "12          LightGBM_BAG_L2       0.784615   0.752896    accuracy        0.391489       0.685581  105.419938                 0.031939                0.016694          11.492439            2       True         12\n",
      "13  RandomForestGini_BAG_L1       0.753846   0.704633    accuracy        0.047975       0.087151    0.533288                 0.047975                0.087151           0.533288            1       True          5\n",
      "14    KNeighborsUnif_BAG_L1       0.723077   0.652510    accuracy        0.009931       0.065917    0.047776                 0.009931                0.065917           0.047776            1       True          1\n",
      "15    KNeighborsDist_BAG_L1       0.707692   0.652510    accuracy        0.010874       0.031592    0.047635                 0.010874                0.031592           0.047635            1       True          2\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 151 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 449 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 449s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240206_123841\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #15~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Jan 12 18:54:30 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       54.04 GB / 62.35 GB (86.7%)\n",
      "Disk Space Avail:   585.30 GB / 915.32 GB (63.9%)\n",
      "===================================================\n",
      "Train Data Rows:    583\n",
      "Train Data Columns: 1024\n",
      "Label Column:       outcome\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    55335.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.28 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['eosce_0', 'eosce_1', 'eosce_2', 'eosce_3', 'eosce_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['eosce_0', 'eosce_1', 'eosce_2', 'eosce_3', 'eosce_4', ...]\n",
      "\t1.6s = Fit runtime\n",
      "\t1024 features in original data used to generate 1024 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.28 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 298.19s of the 447.4s of remaining time.\n",
      "\t0.6792\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 298.04s of the 447.24s of remaining time.\n",
      "\t0.6741\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 297.88s of the 447.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7513\t = Validation score   (accuracy)\n",
      "\t7.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 290.11s of the 439.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.741\t = Validation score   (accuracy)\n",
      "\t14.33s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 275.6s of the 424.8s of remaining time.\n",
      "\t0.6964\t = Validation score   (accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 274.9s of the 424.1s of remaining time.\n",
      "\t0.7015\t = Validation score   (accuracy)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 274.2s of the 423.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7616\t = Validation score   (accuracy)\n",
      "\t104.5s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 169.28s of the 318.48s of remaining time.\n",
      "\t0.6964\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 168.35s of the 317.55s of remaining time.\n",
      "\t0.7067\t = Validation score   (accuracy)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 167.45s of the 316.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 5: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 6: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.7307\t = Validation score   (accuracy)\n",
      "\t4.88s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 162.29s of the 311.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7461\t = Validation score   (accuracy)\n",
      "\t38.45s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 123.5s of the 272.7s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7564\t = Validation score   (accuracy)\n",
      "\t7.49s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 115.75s of the 264.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7496\t = Validation score   (accuracy)\n",
      "\t54.51s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 60.91s of the 210.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 191.\n",
      "\tRan out of time, early stopping on iteration 186.\n",
      "\tRan out of time, early stopping on iteration 200.\n",
      "\tRan out of time, early stopping on iteration 208.\n",
      "\tRan out of time, early stopping on iteration 218.\n",
      "\tRan out of time, early stopping on iteration 227.\n",
      "\tRan out of time, early stopping on iteration 251.\n",
      "\tRan out of time, early stopping on iteration 305.\n",
      "\t0.7616\t = Validation score   (accuracy)\n",
      "\t58.15s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 2.19s of the 151.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, stopping training early. (Stopping on epoch 3)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 1.68s of the 150.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.315068\n",
      "\tTime limit exceeded... Skipping LightGBM_r131_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 1.18s of the 150.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_r191_BAG_L1.\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 0.75s of the 149.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_r9_BAG_L1.\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 0.2s of the 149.4s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1. Best iteration is:\n",
      "\t[1]\tvalid_set's binary_error: 0.315068\n",
      "\tTime limit exceeded... Skipping LightGBM_r96_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 148.61s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.7616\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 148.21s of the 148.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7513\t = Validation score   (accuracy)\n",
      "\t7.93s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 140.05s of the 140.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7719\t = Validation score   (accuracy)\n",
      "\t15.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 124.05s of the 124.01s of remaining time.\n",
      "\t0.7341\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 123.33s of the 123.3s of remaining time.\n",
      "\t0.7341\t = Validation score   (accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 122.62s of the 122.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7856\t = Validation score   (accuracy)\n",
      "\t81.33s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 40.86s of the 40.83s of remaining time.\n",
      "\t0.7136\t = Validation score   (accuracy)\n",
      "\t0.71s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 39.95s of the 39.92s of remaining time.\n",
      "\t0.705\t = Validation score   (accuracy)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 39.06s of the 39.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 2: early stopping\n",
      "No improvement since epoch 7: early stopping\n",
      "No improvement since epoch 4: early stopping\n",
      "\t0.7273\t = Validation score   (accuracy)\n",
      "\t4.54s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 34.23s of the 34.2s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7444\t = Validation score   (accuracy)\n",
      "\t31.67s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 0.53s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 1.0}\n",
      "\t0.7856\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 449.22s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240206_123841\")\n"
     ]
    }
   ],
   "source": [
    "from eosce.models import ErsiliaCompoundEmbeddings\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "train_set = pd.read_csv(os.path.join(DATAPATH, \"training_set_clean.csv\"))\n",
    "y_train = train_set[\"outcome\"]\n",
    "\n",
    "model = ErsiliaCompoundEmbeddings()\n",
    "X_train = model.transform(train_set[\"smiles\"].tolist())\n",
    "X_train = pd.DataFrame(X_train, columns=[\"eosce_{}\".format(i) for i in range(len(X_train[0]))])\n",
    "X_train[\"outcome\"] = y_train #add outcome again for the Tabular Predictor requirement\n",
    "\n",
    "fit_args = {}\n",
    "fit_args['time_limit'] = 600\n",
    "predictor = TabularPredictor(label=\"outcome\").fit(X_train,presets=\"best_quality\", **fit_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240206_133823\"\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
      "Sub-fit(s) time limit is: 600 seconds.\n",
      "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240206_133823/ds_sub_fit/sub_fit_ho.\n",
      "Beginning AutoGluon training ... Time limit = 150s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240206_133823/ds_sub_fit/sub_fit_ho\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #15~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Jan 12 18:54:30 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       52.94 GB / 62.35 GB (84.9%)\n",
      "Disk Space Avail:   585.15 GB / 915.32 GB (63.9%)\n",
      "===================================================\n",
      "Train Data Rows:    518\n",
      "Train Data Columns: 1875\n",
      "Label Column:       outcome\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    54219.21 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.41 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 46 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 210): ['nB', 'nBondsQ', 'nHsssNHp', 'nHmisc', 'nsLi', 'nssBe', 'nssssBem', 'nsBH2', 'nssBH', 'nsssB', 'nssssBm', 'nsssNHp', 'nddsN', 'naOm', 'nsSiH3', 'nssSiH2', 'nsssSiH', 'nssssSi', 'nsPH2', 'nssPH', 'nsssP', 'nddsP', 'nsssssP', 'nssssssS', 'nSm', 'nsGeH3', 'nssGeH2', 'nsssGeH', 'nssssGe', 'nsAsH2', 'nssAsH', 'nsssAs', 'ndsssAs', 'nddsAs', 'nsssssAs', 'nsSeH', 'ndSe', 'nssSe', 'naaSe', 'ndssSe', 'nssssssSe', 'nddssSe', 'nsSnH3', 'nssSnH2', 'nsssSnH', 'nssssSn', 'nsPbH3', 'nssPbH2', 'nsssPbH', 'nssssPb', 'SHsssNHp', 'SHmisc', 'SsLi', 'SssBe', 'SssssBem', 'SsBH2', 'SssBH', 'SsssB', 'SssssBm', 'SsssNHp', 'SddsN', 'SaOm', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SddsP', 'SsssssP', 'SssssssS', 'SSm', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SdsssAs', 'SddsAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SssssssSe', 'SddssSe', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'minHsssNHp', 'minHmisc', 'minsLi', 'minssBe', 'minssssBem', 'minsBH2', 'minssBH', 'minsssB', 'minssssBm', 'minsssNHp', 'minddsN', 'minaOm', 'minsSiH3', 'minssSiH2', 'minsssSiH', 'minssssSi', 'minsPH2', 'minssPH', 'minsssP', 'minddsP', 'minsssssP', 'minssssssS', 'minSm', 'minsGeH3', 'minssGeH2', 'minsssGeH', 'minssssGe', 'minsAsH2', 'minssAsH', 'minsssAs', 'mindsssAs', 'minddsAs', 'minsssssAs', 'minsSeH', 'mindSe', 'minssSe', 'minaaSe', 'mindssSe', 'minssssssSe', 'minddssSe', 'minsSnH3', 'minssSnH2', 'minsssSnH', 'minssssSn', 'minsPbH3', 'minssPbH2', 'minsssPbH', 'minssssPb', 'maxHsssNHp', 'maxHmisc', 'maxsLi', 'maxssBe', 'maxssssBem', 'maxsBH2', 'maxssBH', 'maxsssB', 'maxssssBm', 'maxsssNHp', 'maxddsN', 'maxaOm', 'maxsSiH3', 'maxssSiH2', 'maxsssSiH', 'maxssssSi', 'maxsPH2', 'maxssPH', 'maxsssP', 'maxdsssP', 'maxddsP', 'maxsssssP', 'maxssS', 'maxaaS', 'maxdssS', 'maxddssS', 'maxssssssS', 'maxSm', 'maxsGeH3', 'maxssGeH2', 'maxsssGeH', 'maxssssGe', 'maxsAsH2', 'maxssAsH', 'maxsssAs', 'maxdsssAs', 'maxddsAs', 'maxsssssAs', 'maxsSeH', 'maxdSe', 'maxssSe', 'maxaaSe', 'maxdssSe', 'maxssssssSe', 'maxddssSe', 'maxsSnH3', 'maxssSnH2', 'maxsssSnH', 'maxssssSn', 'maxsI', 'maxsPbH3', 'maxssPbH2', 'maxsssPbH', 'maxssssPb', 'n10Ring', 'n12Ring', 'nF4Ring', 'nF5Ring', 'n10HeteroRing', 'n12HeteroRing', 'nFHeteroRing', 'nF4HeteroRing', 'nF5HeteroRing', 'nTHeteroRing']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 65): ['nBondsD2', 'ndCH2', 'ntCH', 'ndsCH', 'naaCH', 'nsNH3p', 'nsNH2', 'nssNH2p', 'ndNH', 'nssNH', 'naaNH', 'nsOH', 'nsF', 'ndsssP', 'nsSH', 'nsCl', 'nsBr', 'nsI', 'SHsNH3p', 'SHssNH2p', 'SsNH3p', 'SssNH2p', 'minHdNH', 'minHsSH', 'minHsNH3p', 'minHssNH2p', 'minHtCH', 'minHdCH2', 'mindCH2', 'mintCH', 'minddC', 'minsNH3p', 'minssNH2p', 'mindNH', 'minaaO', 'minsSH', 'mindssS', 'maxHdNH', 'maxHsNH3p', 'maxHssNH2p', 'maxHtCH', 'maxHdCH2', 'maxHAvin', 'maxdCH2', 'maxtCH', 'maxddC', 'maxsNH3p', 'maxssNH2p', 'maxdNH', 'maxtN', 'maxaaO', 'maxsSH', 'nT4Ring', 'nT5Ring', 'nT10Ring', 'nT12Ring', 'n4HeteroRing', 'n9HeteroRing', 'n11HeteroRing', 'nG12HeteroRing', 'nT4HeteroRing', 'nT5HeteroRing', 'nT10HeteroRing', 'nT12HeteroRing', 'SRW3']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 65 | ['nBondsD2', 'ndCH2', 'ntCH', 'ndsCH', 'naaCH', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1568 | ['ALogP', 'ALogp2', 'AMR', 'apol', 'nF', ...]\n",
      "\t\t('int', [])   :   32 | ['nAcid', 'naAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 1544 | ['ALogP', 'ALogp2', 'AMR', 'apol', 'nF', ...]\n",
      "\t\t('int', [])       :   32 | ['nAcid', 'naAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', ...]\n",
      "\t\t('int', ['bool']) :   24 | ['nHdNH', 'nHsSH', 'nHsNH3p', 'nHssNH2p', 'nHtCH', ...]\n",
      "\t2.5s = Fit runtime\n",
      "\t1600 features in original data used to generate 1600 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.56s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 98.27s of the 147.43s of remaining time.\n",
      "\t0.6293\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 97.99s of the 147.15s of remaining time.\n",
      "\t0.6429\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 97.72s of the 146.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7568\t = Validation score   (accuracy)\n",
      "\t7.85s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 89.45s of the 138.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7413\t = Validation score   (accuracy)\n",
      "\t15.75s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 73.11s of the 122.27s of remaining time.\n",
      "\t0.7027\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 72.29s of the 121.45s of remaining time.\n",
      "\t0.6931\t = Validation score   (accuracy)\n",
      "\t0.56s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 71.49s of the 120.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 170.\n",
      "\tRan out of time, early stopping on iteration 165.\n",
      "\tRan out of time, early stopping on iteration 183.\n",
      "\tRan out of time, early stopping on iteration 183.\n",
      "\tRan out of time, early stopping on iteration 180.\n",
      "\tRan out of time, early stopping on iteration 197.\n",
      "\tRan out of time, early stopping on iteration 215.\n",
      "\tRan out of time, early stopping on iteration 259.\n",
      "\t0.7413\t = Validation score   (accuracy)\n",
      "\t68.13s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 2.56s of the 51.72s of remaining time.\n",
      "\t0.6969\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1.59s of the 50.75s of remaining time.\n",
      "\t0.6911\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 0.62s of the 49.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 147.44s of the 48.29s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.7568\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 48.03s of the 47.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.751\t = Validation score   (accuracy)\n",
      "\t9.06s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 38.4s of the 38.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7568\t = Validation score   (accuracy)\n",
      "\t14.54s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 23.33s of the 23.29s of remaining time.\n",
      "\t0.6988\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 22.48s of the 22.44s of remaining time.\n",
      "\t0.6911\t = Validation score   (accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 21.65s of the 21.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 47.\n",
      "\tRan out of time, early stopping on iteration 49.\n",
      "\tRan out of time, early stopping on iteration 49.\n",
      "\tRan out of time, early stopping on iteration 53.\n",
      "\tRan out of time, early stopping on iteration 53.\n",
      "\tRan out of time, early stopping on iteration 57.\n",
      "\tRan out of time, early stopping on iteration 62.\n",
      "\tRan out of time, early stopping on iteration 71.\n",
      "\t0.7568\t = Validation score   (accuracy)\n",
      "\t20.34s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 147.44s of the -2.7s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.7568\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 153.1s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240206_133823/ds_sub_fit/sub_fit_ho\")\n",
      "Leaderboard on holdout data from dynamic stacking:\n",
      "                      model  holdout_score  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   RandomForestEntr_BAG_L1       0.800000   0.693050    accuracy        0.044441       0.103586    0.560005                 0.044441                0.103586           0.560005            1       True          6\n",
      "1   RandomForestGini_BAG_L1       0.800000   0.702703    accuracy        0.047346       0.104265    0.583499                 0.047346                0.104265           0.583499            1       True          5\n",
      "2           LightGBM_BAG_L2       0.800000   0.756757    accuracy        0.489364       1.609350  109.042681                 0.025004                0.181795          14.540051            2       True         12\n",
      "3   RandomForestGini_BAG_L2       0.800000   0.698842    accuracy        0.515178       1.534547   95.083929                 0.050818                0.106991           0.581300            2       True         13\n",
      "4   RandomForestEntr_BAG_L2       0.800000   0.691120    accuracy        0.517501       1.531285   95.073822                 0.053142                0.103730           0.571192            2       True         14\n",
      "5         LightGBMXT_BAG_L2       0.784615   0.750965    accuracy        0.496140       1.633512  103.561821                 0.031781                0.205956           9.059191            2       True         11\n",
      "6         LightGBMXT_BAG_L1       0.769231   0.756757    accuracy        0.059507       0.132168    7.852195                 0.059507                0.132168           7.852195            1       True          3\n",
      "7       WeightedEnsemble_L3       0.769231   0.756757    accuracy        0.060412       0.132933    8.224565                 0.000905                0.000765           0.372370            3       True         16\n",
      "8       WeightedEnsemble_L2       0.769231   0.756757    accuracy        0.061251       0.133017    8.104074                 0.001743                0.000849           0.251879            2       True         10\n",
      "9           LightGBM_BAG_L1       0.753846   0.741313    accuracy        0.025706       0.235047   15.746901                 0.025706                0.235047          15.746901            1       True          4\n",
      "10          CatBoost_BAG_L2       0.753846   0.756757    accuracy        0.794379       1.956018  114.846398                 0.330019                0.528462          20.343768            2       True         15\n",
      "11          CatBoost_BAG_L1       0.738462   0.741313    accuracy        0.188822       0.543470   68.133442                 0.188822                0.543470          68.133442            1       True          7\n",
      "12    ExtraTreesEntr_BAG_L1       0.723077   0.691120    accuracy        0.047630       0.111254    0.731962                 0.047630                0.111254           0.731962            1       True          9\n",
      "13    ExtraTreesGini_BAG_L1       0.707692   0.696911    accuracy        0.025595       0.111289    0.726666                 0.025595                0.111289           0.726666            1       True          8\n",
      "14    KNeighborsDist_BAG_L1       0.584615   0.642857    accuracy        0.013364       0.035776    0.082876                 0.013364                0.035776           0.082876            1       True          2\n",
      "15    KNeighborsUnif_BAG_L1       0.569231   0.629344    accuracy        0.011950       0.050702    0.085084                 0.011950                0.050702           0.085084            1       True          1\n",
      "Stacked overfitting occurred: False.\n",
      "Spend 154 seconds for the sub-fit(s) during dynamic stacking.\n",
      "Time left for full fit of AutoGluon: 446 seconds.\n",
      "Starting full fit now with num_stack_levels 1.\n",
      "Beginning AutoGluon training ... Time limit = 446s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240206_133823\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #15~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Fri Jan 12 18:54:30 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       53.12 GB / 62.35 GB (85.2%)\n",
      "Disk Space Avail:   585.16 GB / 915.32 GB (63.9%)\n",
      "===================================================\n",
      "Train Data Rows:    583\n",
      "Train Data Columns: 1875\n",
      "Label Column:       outcome\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    54403.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.34 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 44 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 210): ['nB', 'nBondsQ', 'nHsssNHp', 'nHmisc', 'nsLi', 'nssBe', 'nssssBem', 'nsBH2', 'nssBH', 'nsssB', 'nssssBm', 'nsssNHp', 'nddsN', 'naOm', 'nsSiH3', 'nssSiH2', 'nsssSiH', 'nssssSi', 'nsPH2', 'nssPH', 'nsssP', 'nddsP', 'nsssssP', 'nssssssS', 'nSm', 'nsGeH3', 'nssGeH2', 'nsssGeH', 'nssssGe', 'nsAsH2', 'nssAsH', 'nsssAs', 'ndsssAs', 'nddsAs', 'nsssssAs', 'nsSeH', 'ndSe', 'nssSe', 'naaSe', 'ndssSe', 'nssssssSe', 'nddssSe', 'nsSnH3', 'nssSnH2', 'nsssSnH', 'nssssSn', 'nsPbH3', 'nssPbH2', 'nsssPbH', 'nssssPb', 'SHsssNHp', 'SHmisc', 'SsLi', 'SssBe', 'SssssBem', 'SsBH2', 'SssBH', 'SsssB', 'SssssBm', 'SsssNHp', 'SddsN', 'SaOm', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SddsP', 'SsssssP', 'SssssssS', 'SSm', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SdsssAs', 'SddsAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SssssssSe', 'SddssSe', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'minHsssNHp', 'minHmisc', 'minsLi', 'minssBe', 'minssssBem', 'minsBH2', 'minssBH', 'minsssB', 'minssssBm', 'minsssNHp', 'minddsN', 'minaOm', 'minsSiH3', 'minssSiH2', 'minsssSiH', 'minssssSi', 'minsPH2', 'minssPH', 'minsssP', 'minddsP', 'minsssssP', 'minssssssS', 'minSm', 'minsGeH3', 'minssGeH2', 'minsssGeH', 'minssssGe', 'minsAsH2', 'minssAsH', 'minsssAs', 'mindsssAs', 'minddsAs', 'minsssssAs', 'minsSeH', 'mindSe', 'minssSe', 'minaaSe', 'mindssSe', 'minssssssSe', 'minddssSe', 'minsSnH3', 'minssSnH2', 'minsssSnH', 'minssssSn', 'minsPbH3', 'minssPbH2', 'minsssPbH', 'minssssPb', 'maxHsssNHp', 'maxHmisc', 'maxsLi', 'maxssBe', 'maxssssBem', 'maxsBH2', 'maxssBH', 'maxsssB', 'maxssssBm', 'maxsssNHp', 'maxddsN', 'maxaOm', 'maxsSiH3', 'maxssSiH2', 'maxsssSiH', 'maxssssSi', 'maxsPH2', 'maxssPH', 'maxsssP', 'maxdsssP', 'maxddsP', 'maxsssssP', 'maxssS', 'maxaaS', 'maxdssS', 'maxddssS', 'maxssssssS', 'maxSm', 'maxsGeH3', 'maxssGeH2', 'maxsssGeH', 'maxssssGe', 'maxsAsH2', 'maxssAsH', 'maxsssAs', 'maxdsssAs', 'maxddsAs', 'maxsssssAs', 'maxsSeH', 'maxdSe', 'maxssSe', 'maxaaSe', 'maxdssSe', 'maxssssssSe', 'maxddssSe', 'maxsSnH3', 'maxssSnH2', 'maxsssSnH', 'maxssssSn', 'maxsI', 'maxsPbH3', 'maxssPbH2', 'maxsssPbH', 'maxssssPb', 'n10Ring', 'n12Ring', 'nF4Ring', 'nF5Ring', 'n10HeteroRing', 'n12HeteroRing', 'nFHeteroRing', 'nF4HeteroRing', 'nF5HeteroRing', 'nTHeteroRing']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tUnused Original Features (Count: 63): ['nBondsD2', 'ndCH2', 'ntCH', 'ndsCH', 'naaCH', 'nsNH3p', 'nsNH2', 'nssNH2p', 'ndNH', 'nssNH', 'naaNH', 'nsOH', 'nsF', 'ndsssP', 'nsSH', 'nsCl', 'nsBr', 'nsI', 'SHsNH3p', 'SHssNH2p', 'SsNH3p', 'SssNH2p', 'minHdNH', 'minHsNH3p', 'minHssNH2p', 'minHtCH', 'minHdCH2', 'mindCH2', 'mintCH', 'minddC', 'minsNH3p', 'minssNH2p', 'mindNH', 'minaaO', 'mindssS', 'maxHdNH', 'maxHsNH3p', 'maxHssNH2p', 'maxHtCH', 'maxHdCH2', 'maxHAvin', 'maxdCH2', 'maxtCH', 'maxddC', 'maxsNH3p', 'maxssNH2p', 'maxdNH', 'maxtN', 'maxaaO', 'maxsSH', 'nT4Ring', 'nT5Ring', 'nT10Ring', 'nT12Ring', 'n4HeteroRing', 'n9HeteroRing', 'n11HeteroRing', 'nG12HeteroRing', 'nT4HeteroRing', 'nT5HeteroRing', 'nT10HeteroRing', 'nT12HeteroRing', 'SRW3']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('float', []) : 63 | ['nBondsD2', 'ndCH2', 'ntCH', 'ndsCH', 'naaCH', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1570 | ['ALogP', 'ALogp2', 'AMR', 'apol', 'nF', ...]\n",
      "\t\t('int', [])   :   32 | ['nAcid', 'naAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 1547 | ['ALogP', 'ALogp2', 'AMR', 'apol', 'nF', ...]\n",
      "\t\t('int', [])       :   32 | ['nAcid', 'naAromAtom', 'nAromBond', 'nAtom', 'nHeavyAtom', ...]\n",
      "\t\t('int', ['bool']) :   23 | ['nHdNH', 'nHsNH3p', 'nHssNH2p', 'nHtCH', 'nHdCH2', ...]\n",
      "\t2.4s = Fit runtime\n",
      "\t1602 features in original data used to generate 1602 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.49s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 295.6s of the 443.5s of remaining time.\n",
      "\t0.6398\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 295.34s of the 443.24s of remaining time.\n",
      "\t0.6415\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 295.08s of the 442.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7581\t = Validation score   (accuracy)\n",
      "\t9.72s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 284.93s of the 432.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7547\t = Validation score   (accuracy)\n",
      "\t19.1s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 265.24s of the 413.14s of remaining time.\n",
      "\t0.7187\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 264.4s of the 412.3s of remaining time.\n",
      "\t0.7204\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 263.53s of the 411.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7581\t = Validation score   (accuracy)\n",
      "\t133.22s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 129.8s of the 277.7s of remaining time.\n",
      "\t0.6998\t = Validation score   (accuracy)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 128.66s of the 276.56s of remaining time.\n",
      "\t0.7118\t = Validation score   (accuracy)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 127.62s of the 275.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "No improvement since epoch 3: early stopping\n",
      "No improvement since epoch 8: early stopping\n",
      "No improvement since epoch 5: early stopping\n",
      "\t0.7307\t = Validation score   (accuracy)\n",
      "\t7.01s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 120.17s of the 268.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7564\t = Validation score   (accuracy)\n",
      "\t60.56s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 59.27s of the 207.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7307\t = Validation score   (accuracy)\n",
      "\t19.35s\t = Training   runtime\n",
      "\t2.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 37.65s of the 185.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 155. Best iteration is:\n",
      "\t[76]\tvalid_set's binary_error: 0.219178\n",
      "\tRan out of time, early stopping on iteration 152. Best iteration is:\n",
      "\t[44]\tvalid_set's binary_error: 0.273973\n",
      "\tRan out of time, early stopping on iteration 160. Best iteration is:\n",
      "\t[78]\tvalid_set's binary_error: 0.260274\n",
      "\tRan out of time, early stopping on iteration 166. Best iteration is:\n",
      "\t[57]\tvalid_set's binary_error: 0.273973\n",
      "\tRan out of time, early stopping on iteration 163. Best iteration is:\n",
      "\t[25]\tvalid_set's binary_error: 0.273973\n",
      "\tRan out of time, early stopping on iteration 176. Best iteration is:\n",
      "\t[33]\tvalid_set's binary_error: 0.260274\n",
      "\tRan out of time, early stopping on iteration 181. Best iteration is:\n",
      "\t[29]\tvalid_set's binary_error: 0.232877\n",
      "\tRan out of time, early stopping on iteration 209. Best iteration is:\n",
      "\t[18]\tvalid_set's binary_error: 0.263889\n",
      "\t0.7427\t = Validation score   (accuracy)\n",
      "\t36.05s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1.08s of the 148.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 1.\n",
      "\tTime limit exceeded... Skipping CatBoost_r177_BAG_L1.\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 0.38s of the 148.28s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 145.92s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.7581\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 145.55s of the 145.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7427\t = Validation score   (accuracy)\n",
      "\t9.78s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 135.27s of the 135.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.7599\t = Validation score   (accuracy)\n",
      "\t18.89s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 115.97s of the 115.92s of remaining time.\n",
      "\t0.729\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 115.06s of the 115.01s of remaining time.\n",
      "\t0.7376\t = Validation score   (accuracy)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 114.14s of the 114.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 245.\n",
      "\tRan out of time, early stopping on iteration 259.\n",
      "\tRan out of time, early stopping on iteration 261.\n",
      "\tRan out of time, early stopping on iteration 271.\n",
      "\tRan out of time, early stopping on iteration 302.\n",
      "\t0.777\t = Validation score   (accuracy)\n",
      "\t101.72s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 11.58s of the 11.53s of remaining time.\n",
      "\t0.7256\t = Validation score   (accuracy)\n",
      "\t0.76s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 10.53s of the 10.49s of remaining time.\n",
      "\t0.729\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 9.48s of the 9.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "The 'downcast' keyword in fillna is deprecated and will be removed in a future version. Use res.infer_objects(copy=False) to infer non-object dtype, or pd.to_numeric with the 'downcast' keyword to downcast numeric results.\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 8.63s of the 8.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping XGBoost_BAG_L2.\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 7.23s of the 7.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L2.\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 5.56s of the 5.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 15. Best iteration is:\n",
      "\t[14]\tvalid_set's binary_error: 0.273973\n",
      "\tTime limit exceeded... Skipping LightGBMLarge_BAG_L2.\n",
      "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 4.51s of the 4.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tRan out of time, early stopping on iteration 7.\n",
      "\tTime limit exceeded... Skipping CatBoost_r177_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 0.47s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.923, 'LightGBM_BAG_L2': 0.033, 'RandomForestGini_BAG_L2': 0.033, 'RandomForestEntr_BAG_L2': 0.011}\n",
      "\t0.7787\t = Validation score   (accuracy)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 446.14s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240206_133823\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATAPATH, \"training_set_padel.csv\"))\n",
    "#impute any missing values\n",
    "for column in df.columns[3:]:\n",
    "    column_mean = df[column].mean()\n",
    "    df[column].fillna(column_mean, inplace=True)\n",
    "\n",
    "#change infinity values\n",
    "df.replace([np.inf, -np.inf], 1e6, inplace=True)\n",
    "\n",
    "X_train = df.iloc[:, 2:]\n",
    "\n",
    "fit_args = {}\n",
    "fit_args['time_limit'] = 600\n",
    "predictor = TabularPredictor(label=\"outcome\").fit(X_train,presets=\"best_quality\", **fit_args)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "XkV_8xajbyRf",
    "5JHPytsO5Jez"
   ],
   "provenance": [
    {
     "file_id": "1dPTDhgcUS4fZy4yKlGHy-9D2tKwJfaqd",
     "timestamp": 1704348210233
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
